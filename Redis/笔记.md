# 笔记

## 1.NoSQL概述

### 1.1 为什么要用NoSQL

我们现在正在处于一个大数据时代,而所谓的大数据就是指一般的数据库无法进行分析处理了!

从最开始的历史历程:

> 1、单机MySQL的年代!

这是最早的模型,用户从web端通过数据库访问层去跟数据库交互	

![image-20211009192643907](https://gitee.com/miawei/pic-go-img/raw/master/imgs/image-20211009192643907.png)

90年代,一个基本的网站访问量不会太大,单个数据库完全足够了!而在那个年代的时候,更多的去使用静态网页html~,所以服务器根本没有太大的压力!所以造成了我们的单机MySQL足够使用了。

思考一下？这种情况下：整个网站的瓶颈是什么？

1. 数据库数据量如果太大，一台机器放不下！MySQL存储是有限的;
2. 数据库的单表数据如果超过300万条,那么就一定要建立索引,而索引的底层使用B+Tree实现的,如果索引太大,那么也会造成一台机器内存放不下;
3. 数据库的访问量(读写混合)如果很大的话,那么这个性能也会收到影响,一个服务器承受不了;

以上这些都是在单机MySQL年代的弊端~

> 2、Memcached缓存+MySQL+垂直拆分(读写分离)

​	由于一台机器不够用的时候我们就会扩增服务器,但是我们要保证每台服务器的数据库都是一致的,所以这个时候就提出了一台机器是用于写内容的,另外的服务器用于查询,而修改内容后就会同步到另外的服务器上的数据库里去,所以我们来进行读的时候就可以去1和3里面读,写就去2号里写内容,这样的操作就叫读写分离;

​	网站80%的情况都是在读,每次都要去查询数据库的话就十分的麻烦!所以说我们希望减轻数据库的的压力,我们可以使用缓存来保证效率;缓存只要是解决读的问题,让每次用户如果访问的都是同一SQL,那么就把第一次的数据放到缓存里去,然后后面的再次访问那么就从缓存里获取!

![image-20211009194241743](https://gitee.com/miawei/pic-go-img/raw/master/imgs/image-20211009194241743.png)

发展过程:

1. 最早就是通过优化底层的数据结构、算法和索引的一些东西
2. 然后使用文件缓存的方式,由于文件缓存是IO操作的,并且大文件小文件都要使用IO操作也显得很麻烦
3. 推出了Memcached(当时最热门的技术)

> 3、分库分表+水平拆分+MySQL集群

​	首先从一张图可以看出:数据库服务器发生了改变,这里M:主节点 S:从节点,这里组合成了一个作战单元,也就是组合成一个小节点也是一个小集群,然后小集群就会有多个集群,而我们查询的话正常还是会走缓存,我们整个数据架构就会越来越大,而后台越来越安稳了,那么前台运行就会越来越流畅了,

​	集群怎么实现:比如说我查询一个用户信息,首先会去缓存里看看有没有,没有就去集群里查,如何查呢?首先比如这里3个集群,那么每个集群就会放置用户3分之1的用户数据,加起来就是一个完整的用户数据,而我们通过集群的一些机制就能找到数据在哪个地方,就能提高效率

![image-20211009212552436](https://gitee.com/miawei/pic-go-img/raw/master/imgs/image-20211009212552436.png)

本质:数据库(**读**,**写**),我们始终都在解决这个问题!

- 读:
  - 最开始单机MySQL的时候由于读写都在单机,由于并发量增大造成读的压力变大,我们使用缓存的方式来解决读的问题!

- 写:

  - 物理解决:

    - 早些年使用引擎是MyISM,有个缺点是表锁,那什么是表锁呢?比如说我在一个100万条数据的用户表中查一个数据,那么它就会把整个用户表进行锁起来,剩下的进程由于加锁了只能等待整个查询出来,就会十分的影响效率!高并发下就会出现严重的锁问题,那这个时候就开始转战Innodb!而Innodb是行锁,明显要比表锁效率高得多,行锁就是每次查询就只锁这一行而已!

  - 其他方式解决:

    - 慢慢的就开始使用分库分表来解决写的问题,比如用主从复制、集群的方式!比如说我们一个数据库里有很多表,那么我们就会将这些表按照比如订单、用户、支付不同的业务进行不同的数据库进行管理,如果一个User表里有大量的数据那么也会对字段进行拆分,后面做成了微服务!这个时候就用分库分表就来解决写的压力;

MySQL在那个年代推出了表分区,并没有让很多公司用起来!但是确实给那个年代带来了希望。同时推出了MySQL集群,很好满足了那个年代的所有需求!但是也没有解决大部分需求,因为我们现在数据已经没有那么单一了!

> 4、如今最近的年代

2010-2020十年之间，世界已经发生了翻天覆地的变化（定位，也是一种数据，音乐，热榜!)

像热榜这些动态实时刷新的数据用MySQL集群已经做不了,所以MySQL等关系型数据库就不够用了!因为数据量很多,变化很快!

MySQL有的使用它来存储一些比较大的文件:博客、图片等!就会造成数据库表很大,效率变低了!如果有一种数据库来专门处理这种数据那MySQL的压力就变得十分小(研究如何处理这些问题!),比如在大数据的IO压力下,表几乎无法更改(比如表有一亿条数据,现在增加一列,那么就要增加一亿条数据!);

> 目前一个基本的互联网项目!

从图中可知:用户并不是直接访问的数据库,而是首先访问的是企业防火墙,或者走一些路由网关,那么通过这个网关就要做一些事情就是负载均衡,然后通过负载均衡去搭上我们的服务器集群,通过DNS做一些轮询,通过服务器我们就去访问我们数据库的一些实例,还有我们的很多的服务器!   ![image-20211010090417721](https://gitee.com/miawei/pic-go-img/raw/master/imgs/image-20211010090417721.png)
    

> 为什么要用NoSQL!

用户的个人信息、社交网络、地理位置。用户自己产生的数据(每天都是按TB来计算的)比如用户日志等等都是爆发性的增长,都是几千万条！关系型数据库已经无法满足需求了，已经达到瓶颈了！

这个时候我们就要使用NoSQL数据库了,NoSQL可以很好的处理以上的情况! 

### 1.2 什么是NoSQL

> NoSQL=Not Only SQL(不仅仅是SQL),泛指非关系型数据库的!

关系型数据库:就好比是表格,主要以行和列来记录的	

​	随着web2.0互联网的诞生!传统的关系型数据库很难对付web2.0时代!比如web2.0的产物:音乐、视频、个人社交的一些东西这些爆发性的东西，特别麻烦！尤其是超大规模的高并发社区！而社区在那个年代一般是指网站的站长之类的，而通常网站的流量得到增长的时候就会暴露出很多难以克服的问题，那么这个时候NoSQL在当今大数据环境下发展的十分迅速.Redis是发展最快的,并且是我们必须掌握的一个技术!

​	很多的数据类型用户的个人信息、社交网络、地理位置。这些数据类型的存储不需要一个固定的格式（就是行跟列，比如我们的地理位置不应该是一个固定的格式而是一个图谱，是动态发展的！），不需要的多余的操作就以横向扩展的（用多台机器实现比如集群）！

​	NoSQL比较典型的一种表现:Map<String,Object>,其中Obeject是能装万事万物的,这个是要以键值对的形式来控制

> NoSQL特点

1. 方便扩展(数据之间没有关系,因为KV键值对简单,很好扩展!),解耦

2. 大数据量高性能(Redis一秒写8万次,读11万条数据,NoSQL的缓存记录级的,就是一个记录可以实时的被刷新,是一种细粒度的缓存,性能会比较高!)

3. 数据类型是多样型的!(不需要事先设计数据库!就是键值对形式,我们可以随取随用!如果数据量十分大的表,很多话人就无法设计了)

   


传统的RDBMS和NoSQL的区别:

1. 传统的RDBMS
   - 结构化组织(行,列)
   - 基本的结构化查询SQL
   - 数据和关系都存在单独的表中
   - 操作语言,数据定义语言
   - 严格的一致性(ACID原则)
   - 基础的事务
   - ...
2. NoSQL
   - 不仅仅是数据
   - 没有固定的查询语言
   - 存储方式多种:键值对存储、列存储、文档存储、图形数据库（社交关系就可以用）
   - 最终一致性（是有误差的，但是只要最终结果一致性就可以了）
   - CAP定理 和 BASE理论,理论完用以实践的是"异地多活",就是保证整个服务器不会宕机,一个服务器挂了不会影响其他的服务器;
   - 保证三高问题:高性能（每秒写8万次..）、高可用和高可扩展
   - ...

最大的区别:关系型数据库我们需要学习SQL语言,非关系型数据库不是固定的,并且非关系数据库有存储方式有四种,而关系型数据库只有一种都放在单独的表中,表里就只有两个东西:行跟列

**真正在公司中的实践:NoSQL+RDBMS 一起使用才是最强的!**

我们学东西不是说学怎么安装,学习一下方法如何调用,那叫学习吗?问下自己学会这个东西了吗?真正的学习就应该是从头到尾认认真真学习完每一步,学习一个新东西就应该知道这个是什么意思?干什么的,它为什么诞生了,有什么优势..

> 了解:3V+3高

大数据时代的3V:主要是描述问题的

1. 海量Volume  :海量的数据
2. 多样Variety  :每种数据库都是不一样的,有聊天信息,聊天的图片信息,地图信息,位置信息这些都是不一样的
3. 实时Velocity  :实时性!比如直播的弹幕所接收到的一种实时性

大数据时代的3高:主要是对程序的要求

1. 高并发 :用户数量的增加和访问 
2. 高可拓 :可拓展性,随时水平拆分,可以搭建集群,一台机器不够了,可以扩展机器来解决
3. 高性能 :保证咱们用户体验和性能! 

   

### 1.3 阿里巴巴网页分析

首先我们进入阿里巴巴网站上可以看到:

![image-20211010103527312](https://gitee.com/miawei/pic-go-img/raw/master/imgs/image-20211010103527312.png)

思考问题:这么多东西难道都是在一个数据库中的吗?

```bash
# 1. 商品信息
	名称、价格、商家信息
	关系性数据库就可以解决了！MySQL、Oracle（淘宝早些年去IOE了！-王坚，推荐文章：阿里云的这群疯子），淘宝内部的MySQL不是大家用的MySQL,因为MySQL底层是组件化的是可以进行热拔插, 所以人家根据自己的业务需求去进行改变MySQL!
	
# 2.商品的描述、评论（文字比较多）
	一般放在文档型数据库中,比如MongDB
	
# 3.图片
	分布式文件系统: FastDFS
	淘宝用自己的 TFS
	Gooale的 GFS
	Hadoop的 HDFS
	阿里云的 oss
	
# 4.商品的关键字(搜索)
	搜索引擎: solr、elasticsearch
	淘宝用的是 ISerach, -多隆(它一个人开发出来的)

# 5.商品热门的波段信息(秒杀)
	内存数据库: Redis、Tair、Memache...
	
# 6.商品的交易,外部的支付接口
	三方应用,比如支付宝接口、银行支付
```

所以说:一个简单的网页背后的技术一定不是那么的简单!

大型互联网应用问题:

1. 数据类型太多了!如果是一个电商网站那么就有这么多东西就要去处理!
2. 数据源繁多.经常重构!每个用户都可以上传自己的东西,在敏捷开发中我们就会接触实时重构这个东西!
3. 数据要改造,大面积改造! 如果改一个SQL,那么有关这个SQL的所有接口都要去改!

### 1.4 NoSQL的四大分类

**KV键值对**

不同公司的使用实现:

- 新浪:Redis
- 美团:Redis+Tair
- 阿里、百度:Redis+memecache

**文档型数据库(bson格式,和json一样只是传输功能不一样是二进制的json)**

- MongoDB
  - MongoDB是一个基于分布式文件存储的数据库,一般用于存储大量的文档,其本身是由C++编写的,主要用于处理大量的文档!
  - MongoDB是一个介于**关系型数据库**和**非关系型数据库**之间的产品!
  - MongoDB是非关系型数据库中功能**最丰富**,**最像**关系型数据库的!

- ConthDB

**列存储数据库**

- HBase
- 分布式文件系统  

**图关系数据库**

不是拿来存储图形的,是用于存储关系的,比如:朋友圈社交网络,广告推荐!

 ![image-20211010140906981](https://gitee.com/miawei/pic-go-img/raw/master/imgs/image-20211010140906981.png)

- Neo4j
- InfoGrid



> 四者对比!

![image-20211010141235929](https://gitee.com/miawei/pic-go-img/raw/master/imgs/image-20211010141235929.png)

## 2.Redis入门

### 2.1 概述

> Redis是什么?

Redis（**Re**mote **Di**ctionary **S**erver )，即远程字典服务!
	是一个开源的使用ANSI [C语言](https://baike.baidu.com/item/C语言)编写、支持网络、可基于内存亦可持久化的日志型、Key-Value[数据库](https://baike.baidu.com/item/数据库/103728)，并提供多种语言的API。

理解:首先Redis是C语言编写的,它支持网络所以我们可以通过HTTP协议来传输东西,它基于内存和持久化的,并且它还是以KV键值对的数据库,还有它提供了多种语言的API,也就是说除了Java语言以外我们可以用其他语言来调用Redis!
	redis会周期性的把更新的数据写入磁盘或者把修改操作写入追加的记录文件，并且在此基础上实现了master-slave(主从)同步

**总之**:它是免费和开源的!是当下最热门的NoSQL技术之一,也被人们称之为结构化数据库!

> Redis能干嘛?

1. 内存存储、持久化，内存中是断电即失，所以持久化很重要（这里有两种机制:rdb,aof）
2. 效率高,可以用于高速缓存
3. 发布订阅系统-可以简单的做一些消息队列的功能
4. 地图信息分析
5. 计时器,计数器(浏览量计算!)
6. ...

> Redis特性

1. 开源
2. 支持多种数据类型
3. 支持持久化并提供多种语言API
4. 提供事务的控制 
5. 支持集群
6. ...



这是需要用到的网站:

1. redis官网:https://redis.io/
2. redis中文网:http://www.redis.cn/

下载地址:

![image-20211010144442496](https://gitee.com/miawei/pic-go-img/raw/master/imgs/image-20211010144442496.png)

**注意**:Window在GitHub上下载(停更很久了)

Redis推荐的都是在Linux服务器上搭建的,所以最好是基于Linux来进行学习

### 2.2 安装

> 这是Window下的安装

1. 下载安装包:https://github.com/dmajkic/redis/releases

2. 下载并解压安装包:

   ![image-20211010145305029](https://gitee.com/miawei/pic-go-img/raw/master/imgs/image-20211010145305029.png)

3. 解压后如以下目录:

   ![image-20211010145816869](https://gitee.com/miawei/pic-go-img/raw/master/imgs/image-20211010145816869.png)

   从图中我们看出:

   1. `redis-cli.exe`跟`redis-server.exe`是客户端和服务端
   2. `redis-check-aof.exe`是检查aop持久化文件是不是对的
   3. `redis-benchmark.exe`是测试性能的

4. 开启Rdis,双击`redis-server.exe`即可

   ![image-20211010150200975](https://gitee.com/miawei/pic-go-img/raw/master/imgs/image-20211010150200975.png)

5. 使用redis客户端来连接redis

   ![image-20211010150601350](https://gitee.com/miawei/pic-go-img/raw/master/imgs/image-20211010150601350.png)

   这里我们通过输入命令`ping`返回PONG表示已经连接成功了,然后我们输入set基本值 key-value,然后我们就可以通过key来获取value

> 注意:window下使用很简单,但是Redis官方推荐我们使用Linux去开发使用!

这是官方说明地址:http://www.redis.cn/topics/introduction.html

![image-20211010151343652](https://gitee.com/miawei/pic-go-img/raw/master/imgs/image-20211010151343652.png)

> 这是Linux安装

由于我还没安装Linux进行学习,这里只是作为笔记,未来可回头查阅

1. 下载到本地资源:

![image-20211010152018242](https://gitee.com/miawei/pic-go-img/raw/master/imgs/image-20211010152018242.png)

算了,这里附上链接,学完Linux后再来这里进行安装:

https://www.bilibili.com/video/BV1S54y1R7SB?p=9&spm_id_from=pageDriver

### 2.3 测试性能

在我们的文件夹中找到`redis-benchmark`,这是官方自带的性能测试工具,也是一个压力测试工具!

这是对应的命令参数:

![image-20211010153826476](https://gitee.com/miawei/pic-go-img/raw/master/imgs/image-20211010153826476.png)

我们简单测试一下:

```bash
# 测试:100个并发连接,每个连接都是100000个请求
redis-benchmark -h localhost -p 6379 -c 100 -n 100000
```

![image-20211010171117790](https://gitee.com/miawei/pic-go-img/raw/master/imgs/image-20211010171117790.png)

如何查看这些分析呢？

![image-20211010171633047](https://gitee.com/miawei/pic-go-img/raw/master/imgs/image-20211010171633047.png)

### 2.4 基础的知识

> redis默认有16个数据库!

我们可以打开我们Redis配置文件中的`redis.windows-service.conf`用记事本打开:

![image-20211010172253285](https://gitee.com/miawei/pic-go-img/raw/master/imgs/image-20211010172253285.png)

默认使用的是第0个,我们可以使用`select`进行切换数据库,并且可以使用`DBSIZE`:当前数据库的大小:

```bash
127.0.0.1:6379> ping # 检查当前客户端是否连接上服务器
PONG
127.0.0.1:6379> select 3 # 切换数据库
OK
127.0.0.1:6379[3]> DBSIZE # 这里查看3号数据库大小
(integer) 0
127.0.0.1:6379[3]> set bane Miao # set键值对
OK
127.0.0.1:6379[3]> DBSIZE # 再次查看就可以看到有值
(integer) 1
127.0.0.1:6379[3]> select 7
OK
127.0.0.1:6379[7]> get name
(nil)
127.0.0.1:6379[7]> select 3
OK
127.0.0.1:6379[3]> get bane
"Miao"
127.0.0.1:6379[3]>
```

不同的数据可以存不同的数据库;

> 基础命令:这些命令要记住,后面用Java实现的时候就是用这些命令命名的

1. 查看当前数据库所有的key:**keys *`**

   ```bash
   127.0.0.1:6379[3]> keys *
   1) "bane"
   ```

2. 清除当前数据库:**flushdb **

   ```bash
   127.0.0.1:6379[3]> flushdb 
   OK
   127.0.0.1:6379[3]> keys *
   (empty list or set)
   ```

3. 清除全部数据库:**flushAll**

   ```bash
   127.0.0.1:6379> select 1
   OK
   127.0.0.1:6379[1]> set name MiaoDaWei
   OK
   127.0.0.1:6379[1]> get name
   "MiaoDaWei"
   127.0.0.1:6379[1]> select 2
   OK
   127.0.0.1:6379[2]> set kk HowAreYou
   OK
   127.0.0.1:6379[2]> get kk
   "HowAreYou"
   127.0.0.1:6379[1]> flushAll # 清除全部数据库
   OK
   (0.52s)
   127.0.0.1:6379[1]> get name
   (nil)
   127.0.0.1:6379[1]> select 2
   OK
   127.0.0.1:6379[2]> get kk
   (nil)
   ```

4. 判断key是否存在:**exists**

   ```bash
   127.0.0.1:6379> set name miaowei
   OK
   127.0.0.1:6379> get name
   "miaowei"
   127.0.0.1:6379> exists name # 查询是否存在
   (integer) 1
   127.0.0.1:6379> exists name1 
   (integer) 0
   ```

5. 移动Key:**move**

   ```bash
   127.0.0.1:6379> move name # 移除key 后面没指定数据库表示移除,而如果表明了数据库db,那么这是移动key
   (integer) 1
   127.0.0.1:6379> get name
   (nil)
   ```

6. 给key设置过期时间:**expire**和查看剩余多少秒过期:**ttl**

   ```bash
   127.0.0.1:6379> keys * # 查看所有key
   1) "age"
   2) "name"
   127.0.0.1:6379> expire name 5 # 设置key为name的有效时间为5秒
   (integer) 1
   127.0.0.1:6379> ttl name
   (integer) 3 # 为整数表示剩余多少秒就过期了
   127.0.0.1:6379> ttl name # 查看key的剩余时间
   (integer) -2 # 为-2表示已经不存在了
   127.0.0.1:6379> get name # 获取key
   (nil)
   127.0.0.1:6379> ttl age
   (integer) -1 # 为-1表示永不过期
   ```

   

思考?为什么redis是6379!

这东西,百度就能搜到,似乎是作者为了一舞女还是前女友在九宫格键盘上打出她的名字,就是6379!

> Redis是单线程的!

​	首先我们得知道Redis很快的(这是从官方测试性能得出的),官方表示:Redis是基于内存操作,而CPU不是Redis性能瓶颈,我们知道多线程是跟CPU是挂钩的而Redis是基于内存的,所以说Redis瓶颈是**机器的内存**和**网络带宽**(因为要通过网络接收)决定的!

​	既然可以使用单线程实现就不会用多线程来做!所以就使用了单线程!

> Redis为什么单线程还这么快?

首先我们知道Redis是C语言写的,官方提供的数据为 10000+ 的QPS(每秒查询率),完全不比同样是使用key-value的Memecache差!所以我们就要思考它为什么就那么快?

误区:

1. 高性能的服务器一定是多线程的?不一定
2. 多线程(CPU上下文会切换!!)一定比单线程效率高?不一定
   - 注意:运行速度是:CPU>内存>硬盘

解答:

​	首先明白多线程不一定就会比单线程快!Redis是将所有的数据存放在内存中的,所以说使用单线程操作效率就是最高的!因为多线程之间会造成会产生CPU上下文切换,这个是耗时的操作,因为每次切换都会耗时1500-2000纳秒之间,而一旦多了就会耗时变长了!!!对于内存系统来说,如果没有上下文切换,效率就是最高的!

​	redis利用单个CPU的一块内存的数据的话,针对这块内存进行多次读写的话都是在一个CPU上完成的,多次读写都是在一个CPU上的,在内存情况下,这个就是最佳的方案!

## 3.数据类型

官方文档:

![image-20211010184714617](https://gitee.com/miawei/pic-go-img/raw/master/imgs/image-20211010184714617.png)

全段翻译:

```
Redis 是一个开源（BSD许可）的，内存中的数据结构存储系统，它可以用作数据库、缓存和消息中间件。 它支持多种类型的数据结构，如 字符串（strings）， 散列（hashes）， 列表（lists）， 集合（sets）， 有序集合（sorted sets） 与范围查询， bitmaps， hyperloglogs 和 地理空间（geospatial） 索引半径查询。 Redis 内置了 复制（replication），LUA脚本（Lua scripting）， LRU驱动事件（LRU eviction），事务（transactions） 和不同级别的 磁盘持久化（persistence）， 并通过 Redis哨兵（Sentinel）和自动 分区（Cluster）提供高可用性（high availability）。
```

五大数据类型:

Redis-Key

2. String
3. List
4. Set
5. Hash
6. Zset

三种特殊数据类型

1. geospatial
2. hyperloglog
3. bitmaps 

### 3.1 Redis-Key

```bash
127.0.0.1:6379> keys * # 查看当前库所有的key
(empty list or set)
127.0.0.1:6379> set name miao # set key
OK
127.0.0.1:6379> keys *
1) "name"
127.0.0.1:6379> set age 1
OK
127.0.0.1:6379> keys *
1) "age"
2) "name"
127.0.0.1:6379> EXISTS name  # 查看key是否存在
(integer) 1 # 存在为1
127.0.0.1:6379> EXISTS name1 
(integer) 0 # 不存在为0
127.0.0.1:6379> move name 1 # 移动key到 1号数据库去,这里如果不写数据库index,那么是移除掉
(integer) 1 # 移动成功
127.0.0.1:6379> keys *
1) "age"
127.0.0.1:6379> set name wei
OK
127.0.0.1:6379> keys *
1) "age"
2) "name"
127.0.0.1:6379> get name
"wei"
127.0.0.1:6379> expire name 10 # 设置key的有效过期时间
(integer) 1
127.0.0.1:6379> ttl name # 查看key的剩余时间,单位是秒
(integer) 7
127.0.0.1:6379> ttl name
(integer) 4 # 整数,表示剩余秒数
127.0.0.1:6379> ttl name
(integer) -2 # 为-2,表示已经不存在了
127.0.0.1:6379> ttl age
(integer) -1 # 为-1,表示不会过期
127.0.0.1:6379> get name
(nil)
127.0.0.1:6379> clear # 用于清除在客户端窗口中使用过的记录
127.0.0.1:6379> type name # 用于查看key的数据类型
string
127.0.0.1:6379> type age
string
```

注意:我们在使用的时候,一般redis都会给出相应的提示,也就是所谓的帮助文档,比如我们写一个set,那么就会相应给出提示剩余该怎么写!

如果我们的命令太多记不住,那么我们可以去官网去查看:

![image-20211010193053218](https://gitee.com/miawei/pic-go-img/raw/master/imgs/image-20211010193053218.png)

> 对应的命令一定要记住!因为后面用Jedis后,我们用Java去实现,那么对应的方法跟命令是一样的!

### 3.2 五种数据类型

#### 1. String(字符串类型)

基本命令:

```bash
####################################################################################################################
127.0.0.1:6379> set key1 v1 		# 设置值
OK
127.0.0.1:6379> get key1 			# 获得值
"v1"
127.0.0.1:6379> keys * 				# 查看所有key
1) "key1"
127.0.0.1:6379> exists key1			# 判断某个key是否存在
(integer) 1
127.0.0.1:6379> append key1 'hello' # 追加字符串,如果当前key不存在,就相当于set了一个key
(integer) 7
127.0.0.1:6379> get key1
"v1hello"
127.0.0.1:6379> strlen key1  		# 获取字符串的长度!
(integer) 7
127.0.0.1:6379> append key1 ',MiaoDaWei'
(integer) 17
127.0.0.1:6379> strlen key1
(integer) 17
127.0.0.1:6379> get key1
"v1hello,MiaoDaWei"
####################################################################################################################
# 步长,java中的i+=操作,可以用于网页浏览量等等!
# 注意:使用incr 只能是数字!
127.0.0.1:6379> set views 0  		# 设置初始浏览量为0
OK
127.0.0.1:6379> get views
"0"
127.0.0.1:6379> incr views 			# 自增1
(integer) 1
127.0.0.1:6379> incr views
(integer) 2
127.0.0.1:6379> get views
"2"
127.0.0.1:6379> decr views 			# 自减1
(integer) 1
127.0.0.1:6379> decr views
(integer) 0
127.0.0.1:6379> decr views
(integer) -1
127.0.0.1:6379> decr views
(integer) -2
127.0.0.1:6379> incrby views 12 	# 设置步长,指定增量!在原来基础+12
(integer) 10
127.0.0.1:6379> get views
"10"
127.0.0.1:6379> decrby views 10 	# 设置步长,指定减量!在原来基础上-10
(integer) 0
127.0.0.1:6379> get views
"0"
####################################################################################################################
# 字符串范围操作 range
127.0.0.1:6379> set name "hello,MiaoDaWei" 	# 设置key
OK
127.0.0.1:6379> get name
"hello,MiaoDaWei"
127.0.0.1:6379> getrange name 0 4 			# 截取key的范围,下标从0开始,这是闭区间[0,4]
"hello"
127.0.0.1:6379> get name
"hello,MiaoDaWei"
127.0.0.1:6379> getrange name 0 -1 			# 截取key的范围,结束下标为-1,表示截取整个字符串
"hello,MiaoDaWei"
替换!类似于Java中的subString跟replace:
127.0.0.1:6379> set name2 abcdefg
OK
127.0.0.1:6379> setrange name2 1 xx			# 替换指定位置的开始的字符串!
(integer) 7
127.0.0.1:6379> get name2
"axxdefg"
####################################################################################################################
# setex跟setnx,用于判断当前值是否存在,存在就设值,
# setex(set with expire) :设置过期时间
# setnx(set if not exist):不存在就设值 (在分布式锁中会常常使用!可以保证值的存在)
127.0.0.1:6379> setex key3 30 'hello'		#设置key3的值为hello,并且30秒后过期,注意:key3如果存在就会替换,不存在就会创建,总之只要setex就会有值
OK
127.0.0.1:6379> ttl key3
(integer) 22
127.0.0.1:6379> get key3
"hello"
127.0.0.1:6379> setnx mykey "redis" 		# 如果mykey不存在,就创建mykey
(integer) 1
127.0.0.1:6379> keys *
1) "name"
2) "mykey"
3) "name2"
127.0.0.1:6379> ttl key3
(integer) -2
127.0.0.1:6379> setnx mykey "MongoDB"		# 如果mykey存在,那么创建失败!
(integer) 0
127.0.0.1:6379> get mykey
"redis"
####################################################################################################################
# mset:批量set值
# mget:批量获取值
127.0.0.1:6379>  mset k1 v1 k2 v2 k3 v3		# 批量设置值,以空格隔开,前面是key 后面是value
OK
127.0.0.1:6379> keys *
1) "k1"
2) "k3"
3) "k2"
127.0.0.1:6379> mset k4 v4 k4 v5			# 如果在批量set的时候,key重复了那么就会以后面创建的为准,也就是后面替换前面的
OK
127.0.0.1:6379> get k4
"v5"
127.0.0.1:6379> mget k1 k2 k3 k4 k5			# 批量获取key,都是key并且以空格隔开,有值就获取没值获取不到
1) "v1"
2) "v2"
3) "v3"
4) "v5"
5) (nil)
127.0.0.1:6379>  mset k1 v1 k5 v5
OK
127.0.0.1:6379> msetnx k1 v1 k6 v6			# 批量操作set值,这里是原子性,但凡在批量操作中出现已经存在的key那么就会操作失败返回0,要么同时成功要么同时失败!
(integer) 0

# 对象
set user:1 {name:zhangsan,age:3}  # 设置一个user:1对象 值为json字符来保存一个对象!

# 这里key是一个巧妙的设计:	user:{id}:{filed},如此设计在Redis中是完全是OK的!

127.0.0.1:6379> mset user:1:name zhangsan user:1:age 2
OK
127.0.0.1:6379> mget user:1:name user:1:age
1) "zhangsan"
2) "2"
####################################################################################################################
getset # 先get然后再set
127.0.0.1:6379> getset db redis				# 先获取db在set值,也就是说先获取,不管是否存在都不影响后面的set,如果不存在值就返回null.存在就设置新的值
(nil)
127.0.0.1:6379> get db
"redis"
127.0.0.1:6379> getset db mongodb			# 获取存在的key,然后set值
"redis"
127.0.0.1:6379> get db
"mongodb"
```

其实本身数据结构都是相通的,后面我们就要使用`jedis`中在java中把命令变成一个个的方法!

String类型的使用场景:value除了是我们的字符串还可以是我们的数字!

- 比如计数器
- 统计多单位的数量
- 对象缓存存储!
- 粉丝数!

#### 2. List(列表)

这是一个基本的数据类型->列表

![image-20211010205513293](https://gitee.com/miawei/pic-go-img/raw/master/imgs/image-20211010205513293.png)

在redis里面,我们可以把list玩成:栈、队列、阻塞队列！

常用命令：

**注意**：所有的list命令都是以`l`开头的,并且不区分大小写命令:

```bash
####################################################################################################################
# 这里list只是key的名称而已
127.0.0.1:6379> lpush list one			# 将一个值或多个值插入到列表头部(左)
(integer) 1
127.0.0.1:6379> lpush list two
(integer) 2
127.0.0.1:6379> lpush list three
(integer) 3
127.0.0.1:6379> lrange list 0 -1
1) "three"
2) "two"
3) "one"
127.0.0.1:6379> lrange list 0 1
1) "three"
2) "two"
127.0.0.1:6379> rpush list righr		# 将一个值或多个值插入到列表尾部(右)
(integer) 4
127.0.0.1:6379> lrange list 0 -1
1) "three"
2) "two"
3) "one"
4) "righr"
# 理解:可以想象成一个平面图,使用lpush就会往左边插入,后面的值插入就会让前一个值往右移一位!,rpush反之亦然
####################################################################################################################
LPOP:# 往左边移除
RPOP:# 往右边移除 ,其实可以理解数据结构中的队列
127.0.0.1:6379> lrange list 0 -1
1) "three"
2) "two"
3) "one"
4) "righr"
127.0.0.1:6379> lpop list				# 移除列表的第一个元素
"three"
127.0.0.1:6379> rpop list				# 移除列表的最后一个元素
"righr"
127.0.0.1:6379> lrange list 0 -1
1) "two"
2) "one"
####################################################################################################################
# 理解为数组的话我们可以通过下标来获取值
lindex :# 获取某一个列表的下标值
127.0.0.1:6379> lrange list 0 -1		# 获取列表全部元素
1) "two"
2) "one"
127.0.0.1:6379> lindex list 0			# 获取下标为0的元素
"two"
127.0.0.1:6379> lindex list 1
"one"
127.0.0.1:6379> lindex list 2			# 因为下标没有元素所以返回null
(nil)
####################################################################################################################
Llen:# 获取列表的长度
127.0.0.1:6379> lpush list one two three # 往列表里插入多个值
(integer) 3
127.0.0.1:6379> llen list				 # 获取列表的长度,也就是有多少个元素
(integer) 3
####################################################################################################################
lrem:# 移除指定的值!
127.0.0.1:6379> lpush list three		# 往列表头部插入一个元素
(integer) 4
127.0.0.1:6379> lrange list 0 -1
1) "three"
2) "three"
3) "two"
4) "one"
127.0.0.1:6379> lrem list 1 one			# 移除列表中指定个数的value,精确匹配!注意:如果指定个数比实际个数多了,也不会影响!
(integer) 1
127.0.0.1:6379> lrange list 0 -1
1) "three"
2) "three"
3) "two"
127.0.0.1:6379> lrem list 2 three
(integer) 2
127.0.0.1:6379> lrange list 0 -1
1) "two"
####################################################################################################################
ltrim: # 截断某一部分的数据
127.0.0.1:6379> rpush list "hello"
(integer) 1
127.0.0.1:6379> rpush list "hello1"
(integer) 2
127.0.0.1:6379> rpush list "hello2"
(integer) 3
127.0.0.1:6379> rpush list "hello3"
(integer) 4
127.0.0.1:6379> lrange list 0 -1
1) "hello"
2) "hello1"
3) "hello2"
4) "hello3"
127.0.0.1:6379> ltrim list 1 2			# 通过下标截取指定的长度!这个list截取后就已经发生了改变,截断后只剩下截取的元素!
OK
127.0.0.1:6379> lrange list 0 -1
1) "hello1"
2) "hello2"
####################################################################################################################
rpoplpush: # 移除列表最后一个元素并将该元素添加到新的列表头部并返回,这是一个组合命令
127.0.0.1:6379> rpush mulist "hello"
(integer) 1
127.0.0.1:6379> rpush mulist "hello1"
(integer) 2
127.0.0.1:6379> rpush mulist "hello2"
(integer) 3
127.0.0.1:6379> lrange mulist 0 -1
1) "hello"
2) "hello1"
3) "hello2"
127.0.0.1:6379> rpoplpush mulist list		# 将当前列表尾部的元素移除,然后将移除的元素push到另一个列表的头部	
"hello2"
127.0.0.1:6379> lrange mulist 0 -1			# 查看原来的列表
1) "hello"
2) "hello1"
127.0.0.1:6379> lrange list 0 -1			# 查看目标列表中,确实存在改值!
1) "hello2"
####################################################################################################################
lset: # 往存在的列表中对指定下标的值进行替换为另外一个值进行更新操作
127.0.0.1:6379> exists list					# 判断这个列表是否存在
(integer) 0
127.0.0.1:6379> lset list 0 miao			# 更新不存在的列表就会报错
(error) ERR no such key
127.0.0.1:6379> lpush list value1
(integer) 1
127.0.0.1:6379> lrange list 0 0
1) "value1"
127.0.0.1:6379> lset list 0 miao			# 如果存在就会更新当前下标的值
OK
127.0.0.1:6379> lrange list 0 0
1) "miao"
127.0.0.1:6379> lset list 1 wei				# 更新不存在的下标就会提示报错!
(error) ERR index out of range
####################################################################################################################
linsert: # 将某个具体的value插入到列表中具体的某个元素的	前面/后面
127.0.0.1:6379> rpush mylist "hello"
(integer) 1
127.0.0.1:6379>  rpush mylist "hello1"
(integer) 2
127.0.0.1:6379> linsert mylist before "world" "other"		# 在列表中指定的元素前面插入value
(integer) -1
127.0.0.1:6379> linsert mylist before "hello1" "other"
(integer) 3
127.0.0.1:6379> lrange mylist 0 -1
1) "hello"
2) "other"
3) "hello1"
127.0.0.1:6379> linsert mylist after "hello1" "after"		# 在列表中指定的元素后面插入value
(integer) 4
127.0.0.1:6379> lrange mylist 0 -1
1) "hello"
2) "other"
3) "hello1"
4) "after"
```

> 小结

1. 它实际上是一个链表的结构,我们可以在指定的节点的前后进行操作 before Node after,left right都可以插入值
2. 在push的时候如果key不存在就会创建新的链表!
3. 如果key存在,就会新增内容
4. 如果移除了所有的值就会变成一个空链表,而一个空链表就代表不存在!
5. 在两边插入或者改动值,效率是最高的!如果改动中间元素效率相对会低!



一般应用场景为消息排队、消息队列;

我们可以把列表当成队列使用:`Lpush Rpop` 先进先出

​			   堆栈使用:`Lpush Lpop` 先进后出	

这是列表最大的**优势**:既可以当成栈也可以当成队列!

#### 3. Set(集合)

这个Set也是一个集合类型可以存储多个值,但是**不能重复**!

基本命令:

**Set数据类型都是以S开头的命令,多以member表示元素**

```bash
####################################################################################################################
sadd:# 添加元素
smembers: # 查看所有元素
sismember: # 判断是否包含指定元素

127.0.0.1:6379> sadd myset "hello"				# set集合中添加元素
(integer) 1
127.0.0.1:6379> sadd myset "hello1"
(integer) 1
127.0.0.1:6379> sadd myset "hello1"				# 重复添加就会失败!
(integer) 0
127.0.0.1:6379> smembers myset					# 查看指定set的所有值
1) "hello"
2) "hello1"
127.0.0.1:6379> sismember myset "hello"			# 判断某个元素是否在set中
(integer) 1
127.0.0.1:6379> sismember myset "world"
(integer) 0
####################################################################################################################
127.0.0.1:6379> scard myset						# 获取set集合中内容元素个数
(integer) 2
127.0.0.1:6379> sadd myset "MiaoDaWei"
(integer) 1
127.0.0.1:6379> scard myset
(integer) 3
####################################################################################################################
srem: # 移除set集合中指定的一个元素

127.0.0.1:6379> scard myset
(integer) 3
127.0.0.1:6379> srem myset hello				# 移除set集合中指定元素
(integer) 1
127.0.0.1:6379> scard myset
(integer) 2
127.0.0.1:6379> smembers myset					# 查看set中全部元素
1) "hello1"
2) "MiaoDaWei"
####################################################################################################################
set 无序不重复集合。抽随机！
srandmember: # 随机抽取元素,可以指定抽取个数-由于数据量少容易出现偶然性

127.0.0.1:6379> smembers myset
1) "hello"
2) "hello1"
3) "MiaoDaWei"
127.0.0.1:6379> srandmember myset				# 随机抽选一个元素
"MiaoDaWei"
127.0.0.1:6379>  srandmember myset
"hello1"
127.0.0.1:6379>  srandmember myset 2			# 随机抽选出指定个数的元素
1) "hello1"
2) "MiaoDaWei"
127.0.0.1:6379>  srandmember myset 2
1) "hello1"
2) "MiaoDaWei"
127.0.0.1:6379>  srandmember myset 2
1) "hello"
2) "MiaoDaWei"
####################################################################################################################
# 删除随机的元素

127.0.0.1:6379> smembers myset
1) "hello"
2) "hello1"
3) "MiaoDaWei"
127.0.0.1:6379> spop myset						# 移除Set集合中随机的一个元素,pop:弹出
"hello"
127.0.0.1:6379> spop myset 2					# 移除Set集合中指定个数的随机元素
1) "hello1"
2) "MiaoDaWei"
127.0.0.1:6379> smembers myset
(empty list or set)
####################################################################################################################
# 将一个指定的值移动到另外一个Set集合中!

127.0.0.1:6379> sadd myset "hello"
(integer) 1
127.0.0.1:6379> sadd myset "hello2"
(integer) 1
127.0.0.1:6379> sadd myset "MiaoDaWei"
(integer) 1
127.0.0.1:6379> sadd myset2 "set2"
(integer) 1
127.0.0.1:6379> smembers myset
1) "hello"
2) "hello2"
3) "MiaoDaWei"
127.0.0.1:6379> smembers myset2
1) "set2"
127.0.0.1:6379> smove myset myset2 "MiaoDaWei"			# 将一个指定的值从当前Set集合移动到另外一个Set集合中去!
(integer) 1
127.0.0.1:6379> smembers myset
1) "hello"
2) "hello2"
127.0.0.1:6379> smembers myset2
1) "set2"
2) "MiaoDaWei"
####################################################################################################################
我们的微博或者哔哩哔哩都会发现有共同关注:
数学集合类:
	-  差集
	-  交集
	-  并集	

127.0.0.1:6379> sadd key1 a
(integer) 1
127.0.0.1:6379> sadd key1 b
(integer) 1
127.0.0.1:6379> sadd key1 c
(integer) 1
127.0.0.1:6379> sadd key2 c
(integer) 1
127.0.0.1:6379> sadd key2 d
(integer) 1
127.0.0.1:6379> sadd key2 e
(integer) 1
127.0.0.1:6379> smembers key1
1) "c"
2) "b"
3) "a"
127.0.0.1:6379> smembers key2
1) "d"
2) "c"
3) "e"
127.0.0.1:6379> sdiff key1 key2						# 差集:以第一个Set集合为参照物,然后跟二个Set集合进行比对,然后获取到第一个Set集合中的差集
1) "a"
2) "b"
127.0.0.1:6379> sinter key1 key2					# 交集:获取第一个Set集合与第二个Set集合共同的元素->共同好友就是这样实现的!
1) "c"
127.0.0.1:6379> sunion key1 key2					# 并集:获取第一个Set集合和第二个Set集合中不重复的元素!
1) "a"
2) "b"
3) "c"
4) "d"
5) "e"
####################################################################################################################
```

这里交集的应用场景:

​	比如微博,对于A用户来说将所有关注的人放在一个Set集合中,将它的粉丝也放在一个集合中!共同关注:A用户和B用户的共同关注就可以实现了,我们把这两个关注的人做一个交集,那么就出来了,类似的也有很多,比如共同爱好之类的,

这里提一个概念:二度好友,推荐好友!-->六度分隔理论!



#### 4. Hash(哈希)

​	可以把这想象成一个Map集合!首先我们在Map集合中存储的数据结构是`Key-Value`,而我们则是将value改成`Key-Map`集合!也就是`Key-<key-value>`结构,存储的话也是键值对,只不过这个时候这个值是一个map集合!

​	本质上跟String类型没有太大区别!还是简单的一个key-value!只不过这个值是有两个值进行组合的!

**所有的Hash都是以H开头的命令**

基本命令:

```bash
####################################################################################################################
127.0.0.1:6379> hset myhash filed1 miaowei				# 设置一个key value为一个map
(integer) 1
127.0.0.1:6379> hget myhash filed1						# 获取一个字段值
"miaowei"
127.0.0.1:6379> hset myhash filed2 wei
(integer) 1
127.0.0.1:6379> hget myhash filed2
"wei"
127.0.0.1:6379> hmset myhash filed3 hello filed2 world	 # set 多个key-value
OK
127.0.0.1:6379> hmget myhash filed1 filed2 filed3		# 获取多个字段值
1) "miaowei"
2) "world"
3) "hello"
127.0.0.1:6379> hgetall myhash							# 获取全部的数据,展示的数据以键跟值进行展示
1) "filed1"
2) "miaowei"
3) "filed2"
4) "world"
5) "filed3"
6) "hello"
127.0.0.1:6379> hdel myhash filed1						# 删除hash指定的key字段!对应的value值也就没有了!这里可以批量删除!
(integer) 1
127.0.0.1:6379> hgetall myhash
1) "filed2"
2) "world"
3) "filed3"
4) "hello"
####################################################################################################################
hlen: # 获取hash中有多少个值

127.0.0.1:6379> hgetall myhash
1) "filed2"
2) "world"
3) "filed3"
4) "hello"
127.0.0.1:6379> hlen myhash								# 获取hash表的字段数量
(integer) 2
####################################################################################################################
hexists: # 判断hash中是否有指定的key

127.0.0.1:6379> hgetall myhash
1) "filed2"
2) "world"
3) "filed3"
4) "hello"
127.0.0.1:6379> hexists myhash filed2					# 判断hash中指定字段是否存在!
(integer) 1
127.0.0.1:6379> hexists myhash filed4
(integer) 0
####################################################################################################################
# 只获得所有所有的filed

127.0.0.1:6379> hkeys myhash							# 获取所有的字段
1) "filed2"
2) "filed3"
127.0.0.1:6379> hvals myhash							# 获取所有的value
1) "world"
2) "hello"
####################################################################################################################
incr decr  # 自增

127.0.0.1:6379> hset myhash field3 5					# 指定初始数量
(integer) 1
127.0.0.1:6379> hincrby myhash field3 1					# 指定增量
(integer) 6
127.0.0.1:6379> hincrby myhash field3 -1				# 指定增量为负,就表示为decrby自减
(integer) 5
127.0.0.1:6379> hsetnx myhash field3 hello				# 如果存在则不能设置
(integer) 0
127.0.0.1:6379> hsetnx myhash field4 hello
(integer) 1

注:可以应用在分布式锁中!
```

应用场景:

​	hash变更的数据,我们可以把一个用户user当成一个键,而User里面有很多name和age,那么我们可以把name和age当成我们的值!我们可以把对象作为键,然后里面存放着就是具体的字段和字段的值,这样我们就能通过一个对象就能获取对应的字段!

​	Hash尤其是可以用一些用户信息的保存!特别是经常变动的信息!hash更适合于**对象的存储**!String更加适合字符串的存储!

类似:

```bash
127.0.0.1:6379> hmset user:1 name miaowei age 21
OK
127.0.0.1:6379> hget user:1 name
"miaowei"
127.0.0.1:6379> hget user:1 age
"21"
```

#### 5. Zset(有序集合)

​	在set的基础上增加了一个值,之前是set k1 v1,现在是zset k1 score1 v1,中间多了一个值用于排序!

​	本身跟Set并没有任何区别,这个也是不能重复的,但是这个跟Set明显区别就是多了一个可以用于排序的值!

常用命令(**同样是以Z开头的**):

```bash
####################################################################################################################
127.0.0.1:6379> zadd myzset 1 one					# 添加一个值
(integer) 1
127.0.0.1:6379> zadd myzset 3 three 2 two			# 批量添加多个值
(integer) 2
127.0.0.1:6379> zrange myzset 0 -1					# 查看全部值
1) "one"
2) "two"
3) "three"
####################################################################################################################
# 排序如何实现?

127.0.0.1:6379> zadd salary 2500 xiaohong							# 添加三个用户
(integer) 1
127.0.0.1:6379> zadd salary 5000 zhangsan
(integer) 1
127.0.0.1:6379> zadd salary 500 MiaoDaWei
(integer) 1
127.0.0.1:6379> zrange salary 0 -1									# 查看全部用户,默认是按照中间排序的值进行升序排列
1) "MiaoDaWei"
2) "xiaohong"
3) "zhangsan"
127.0.0.1:6379> zrangebyscore salary -inf +inf						# 查看全部用户通过排序值,并且负无穷到正无穷,也就是从小到大排序
1) "MiaoDaWei"
2) "xiaohong"
3) "zhangsan"
127.0.0.1:6379> zrangebyscore salary 0 -1							# 获取失败,最小值不能超过最大值
(empty list or set)
127.0.0.1:6379> zrangebyscore salary 0 5
(empty list or set)
127.0.0.1:6379> zrangebyscore salary 0 1000							# 这里就是获取1000以下的值
1) "MiaoDaWei"
127.0.0.1:6379> zrangebyscore salary -inf +inf withscores			# 显示最小到最大的用户并且附带成绩,就是有序集合的值
1) "MiaoDaWei"
2) "500"
3) "xiaohong"
4) "2500"
5) "zhangsan"
6) "5000"
127.0.0.1:6379> zrevrange salary 0 -1								# 从大到小进行排序!反转排序
1) "zhangsan"
2) "MiaoDaWei"
####################################################################################################################
# 移除zset中的元素

127.0.0.1:6379> zrange salary 0 -1
1) "MiaoDaWei"
2) "xiaohong"
3) "zhangsan"
127.0.0.1:6379> zrem salary xiaohong								# 移除有序集合中的指定元素
(integer) 1
127.0.0.1:6379> zrange salary 0 -1
1) "MiaoDaWei"
2) "zhangsan"
127.0.0.1:6379> zrange salary 0 -1									# 获取有序集合中的个数
1) "MiaoDaWei"
2) "zhangsan"
127.0.0.1:6379> zcard salary
(integer) 2
####################################################################################################################
# 按区间来计算

127.0.0.1:6379> zadd myset 1 hello 2 world 3 miaowei
(integer) 3
127.0.0.1:6379> zcount myset 1 3									# 获取指定区间的成员数量,包括1到3
(integer) 3
127.0.0.1:6379> zcount myset 1 2
(integer) 2
```

应用场景:

​	Set能做的事情它也能做,Set是无序的,而Zset是有序的,所以我们一般可以存储班级成绩表,工资表排序!我们还可以让一些消息带有权重,比如我们把普通消息设置为1,重要消息设置为2,所以我们可以带权重进行判断!

​	比如我们在B站或者微博热搜排行榜,我们就可以用Zset集合来做,把所有的播放量或者评分放在有序集合中,然后进行遍历,然后每一分钟进行刷新!然后还可以取Top N测试!

### 3.3 三种特殊数据类型

#### 1. geospatial(地理位置)

这种数据类型就可以实现朋友的定位、附近的人、打车的距离计算!

这种特殊类型再很早Redis3.2版本就推出了!这个功能就可以推算出地理位置的信息,两地之间的距离,方圆几里的人!

我们使用这种数据类型需要提供经纬度,所以我们可以查询一些测试数据:http://www.jsons.cn/lngcode/

只有六个命令使用(我们可以把`geospatial`只读前三个单词就是`geo`,然后我们再去看命令,是不是清晰多了):

![image-20211012211029794](https://gitee.com/miawei/pic-go-img/raw/master/imgs/image-20211012211029794.png)

官方文档:https://www.redis.net.cn/order/3685.htm

> geoadd

```bash
# geoadd 添加地理位置
# 规则:南北两极不能直接添加,我们一般会下载城市数据,直接通过Java程序一次性导入!
# 参数 geoadd 中国:城市 经度、纬度 名称
127.0.0.1:6379> geoadd china:city 116.40 39.90 beijing			# 添加城市经纬度
(integer) 1
127.0.0.1:6379> geoadd china:city 121.47 31.23 shanghai
(integer) 1
127.0.0.1:6379> geoadd china:city 106.50 29.53 chongqing 114.05 22.52 sehnzhen
(integer) 2
127.0.0.1:6379> geoadd china:city 120.16 30.21 hangzhou
(integer) 1
127.0.0.1:6379> geoadd china:city 108.96 34.26 xian
(integer) 1
# 这是错误示范,超出了范围:
#有效的经度从-180度到180度。
#有效的纬度从-85.05112878度到85.05112878度。
#当坐标位置超出上述指定范围时，该命令将会返回一个错误
127.0.0.1:6379> geoadd china:city 39.90 116.40  beijing
(error) ERR invalid longitude,latitude pair 39.900000,116.400000
```

> geopos

```bash
# geopos 获取指定城市的经纬度
# 获得当前定位: 一定是一个坐标值
127.0.0.1:6379> geopos china:city beijing			# 获取指定的城市经度和纬度
1) 1) "116.39999896287918"
   2) "39.900000091670925"
127.0.0.1:6379> geopos china:city chongqing hangzhou
1) 1) "106.49999767541885"
   2) "29.529999579006592"
2) 1) "120.16000002622604"
   2) "30.209999363307084"
```

> geoDist

```bash
# geoDist 返回两个给定位置之间的距离
# 如果两个位置之间的其中一个不存在， 那么命令返回空值。
# m 表示单位为米。
# km 表示单位为千米。
# mi 表示单位为英里。
# ft 表示单位为英尺。
# 如果用户没有显式地指定单位参数， 那么 GEODIST 默认使用米作为单位。
127.0.0.1:6379> geodist china:city beijing shanghai				# 查看上海到到北京的直线距离 默认单位为m
"1067378.7564"
127.0.0.1:6379> geodist china:city beijing shanghai km			# 查看上海到北京的直线距离 ,指定单位为km
"1067.3788"
127.0.0.1:6379> geodist china:city chongqing beijing km
"1464.0708"

```

> geoRadius

如何去做附近的人?(首先获得附近的人的地址,进行定位!然后不定时刷新定位把附近的定位加入到集合中!),通过半径进行查询!

注意:所有数据都应该录入key中,如:china:city,才会让结果更加清晰!

```bash
# geoRadius 以给定的经纬度为中心,找出某一半径的元素
127.0.0.1:6379> georadius china:city 110 30 1000 km											# 获取指定key中以 110 30 经纬度为中心,寻找方圆半径1000 km的城市
1) "chongqing"
2) "xian"
3) "sehnzhen"
4) "hangzhou"
127.0.0.1:6379> georadius china:city 110 30 500 km
1) "chongqing"
2) "xian"
127.0.0.1:6379> georadius china:city 110 30 500 km withcoord								# 显示他人的定位信息
1) 1) "chongqing"
   2) 1) "106.49999767541885"
      2) "29.529999579006592"
2) 1) "xian"
   2) 1) "108.96000176668167"
      2) "34.2599996441893"
127.0.0.1:6379> georadius china:city 110 30 500 km withdist									# 显示到中心距离的位置,以11 30 为中心!,就是显示这俩的直线距离
1) 1) "chongqing"
   2) "341.9374"
2) 1) "xian"
   2) "483.8340"
127.0.0.1:6379> georadius china:city 110 30 500 km withdist withcoord count 1				# 筛选出指定指定个数的结果
1) 1) "chongqing"
   2) "341.9374"
   3) 1) "106.49999767541885"
      2) "29.529999579006592"
127.0.0.1:6379> georadius china:city 110 30 500 km withdist withcoord count 1 desc			# 筛选出指定个数的结果并按照倒序排列
1) 1) "xian"
   2) "483.8340"
   3) 1) "108.96000176668167"
      2) "34.2599996441893"

```

> georadiusBymember

上面是根据经纬度去找周围人的经纬度,而这个是根据城市与城市之间的定位,我们也可以用做小区与小区之间的定位!

```bash
# georadiusBymember 找出位于指定范围内的元素,中心点是由给定的位置元素决定
127.0.0.1:6379> georadiusBymember china:city beijing 1000 km								# 查找指定城市为中心为半径1000km以内的城市
1) "beijing"
2) "xian"
127.0.0.1:6379>  georadiusBymember china:city shanghai 400 km
1) "hangzhou"
2) "shanghai"
```

> geohash

```bash
# geohash 返回一个或多个位置元素的Geohash表示-了解即可
# 该命令将返回11个字符的Geohash字符串!
# 将经纬度转换为字符串,这个字符串是11位的hash
# 如果两个字符串长得越像越接近,那么则两者距离就越近!
127.0.0.1:6379> geohash china:city beijing chongqing										# 将二维的经纬度转换为一维的字符串
1) "wx4fbxxfke0"
2) "wm5xzrybty0"
```

> GEO 底层的实现原理!

geo底层的实现原理其实就是Zset有序集合!geo这里面每个地址都可以标一个序号!所以说我们可以Zset命令来操作geo!

来看一下如何去实现:

```bash
# 我们看了geo命令是没有删除的,那么再来看这个
# 所以说基本的数据类型是很重要的,像这种特殊数据类型就是基于底层封装的
127.0.0.1:6379> zrange china:city 0 -1					# 查看全部的元素
1) "chongqing"
2) "xian"
3) "sehnzhen"
4) "hangzhou"
5) "shanghai"
6) "beijing"
127.0.0.1:6379> zrem china:city beijing					# 移除指定的元素
(integer) 1
127.0.0.1:6379> zrange china:city 0 -1
1) "chongqing"
2) "xian"
3) "sehnzhen"
4) "hangzhou"
5) "shanghai"
```



#### 2. Hyperloglog(基数统计)

> 什么是基数?

比如说这里有两个集合:A{1,2,3,4,4},B:{1,2,3,4},而基数呢?说直白点就是两个集合共同不重复的元素,这里个数为:four:,所以我们要去两个集合中找不重复的元素,如果数量特别大,是可以有误差的!

> 简介

Redis 2.8.9版本就更新了Hyperloglog这种数据结构!所以它有自己的算法。

Redis Hyperloglog 是用于基数统计的算法！

优点:占用的内存是固定的,比如我们这里存储2^64次方-long类型的最大值,然后我们存储不同的元素的基数,只需要费12kb的内存!

**如果从内存的角度来讲比较的话Hyperloglog就是首选!**

​	比如：统计一个网页的UV(UV:页面访问量),我们这里一个人访问一个网站多次,但是还是要算作一个人!如果不是这样那么我们统计出来就是错误的!

​	传统的方式:我们使用Set集合保存用户的id,如果出现一样的id那么就会被干掉!不允许重复,就可以统计Set集合中的元素数量,作为标准判断,当然也有可能存在误差,比如在并发的时候,但是有的用户id比较麻烦,使用的uuid或者分布式id,这种呢就会导致id特别特别的长,那么这种方式保存大量的用户id就会特别麻烦!占内存!消耗了大量的存储空间去存储,而我们的目的并不是去保存这个的用户id,而是去计数!



官方:在官方文档里提出有0.81%的错误率,统计UV任务是可以忽略不计的!

所有的hyperloglog的基本命令都是以PF开头的:

```bash
# 测试使用:
127.0.0.1:6379> pfadd mykey a b c d e f g h i j				# 创建第一组元素
(integer) 1
127.0.0.1:6379> pfcount mykey								# 统计第一组元素基数数量(重复的话就会被过滤掉,统计的都是不能重复的元素)
(integer) 10
127.0.0.1:6379> pfadd mykey2 i j z x c v b n m
(integer) 1
127.0.0.1:6379> pfcount mykey2
(integer) 9
127.0.0.1:6379> pfmerge mykey3 mykey mykey2					# 合并两组 mykey mykey2 =>mykey3,这里是并集(合并两个集合中不重复的元素合并在一起!),
OK
127.0.0.1:6379> pfcount mykey3								# 查看并集的数量
(integer) 15
```

使用场景:我们使用一些网站的计数,就可以用这个Hyperloglog;比如说每个用户登录上来的就放在这个集合里,表示当前用户,并且后续如果放入当前用户,那么在统计的时候都会进行基数统计,也就是不能重复!

如果允许容错,那么一定可以使用`Hyperloglog`!

如果不允许容错,就使用set或者自己的数据类型即可!

优缺点:

1. 使用set方式在录入的时候就会进行比对,而在大数据量的情况下效率就会变低,并且还会占用内存!
2. 使用Hyperloglog内存是固定的!只有12k!

#### 3. Bitmap(位存储)

> 位存储

常见场景:比如统计用户的信息:在B站中就分为活跃的和不活跃的!还有是登录多少人和未登录多少人的!还有一种场景就是打卡,按照之前纯java实现的话就要去设计数据库表,:userid、status(是否打卡)、data这三个字段,而在Redis中可以Bitmap存储,**只有两个状态的都可以用bitmap**!

​	比如记录打卡365天,365天=365bit, 1字节=8bit ,差不多接近于46个字节左右!! 可以发现这样去做是非常省内存的!而且还能让这个效率变得更高!

Bitmap位图->也是一个数据结构!都是用操作**二进制**位来进行记录!就只有0和1两个状态!

Bitmap其实就是通过位运算来表示元素的值



> 测试

![image-20211013144610439](https://gitee.com/miawei/pic-go-img/raw/master/imgs/image-20211013144610439.png)

比如这里以上画图就是一周的打卡考勤,然后我们用Bitmap来记录周一到周日的打卡:

而我们如果要统计打卡的天数就只需要判断多少天是1就好了;

```bash
127.0.0.1:6379> setbit sign 1 1		# 设置星期一已打卡
(integer) 0
127.0.0.1:6379> setbit sign 2 0		# 设置星期二未打卡
(integer) 0
127.0.0.1:6379> setbit sign 3 0
(integer) 0
127.0.0.1:6379> setbit sign 4 0
(integer) 0
127.0.0.1:6379> setbit sign 5 1
(integer) 0
127.0.0.1:6379> setbit sign 6 1
(integer) 0
127.0.0.1:6379> setbit sign 7 0
(integer) 0
# 错误师范
127.0.0.1:6379> setbit sign 1 2		# 第二个参数只能是0或1,因为二进制就是0和1组成的!
(error) ERR bit is not an integer or out of range
127.0.0.1:6379> setbit sign hello 1	# 第一个参数只能为数字偏移量,不能为其他类型
(error) ERR bit offset is not an integer or out of range
```

查看某一天打卡:

```bash
127.0.0.1:6379> getbit sign 2		# 获取星期二是否打卡
(integer) 0
127.0.0.1:6379> getbit sign 7
(integer) 0
127.0.0.1:6379> getbit sign 1		# 获取星期1是否打卡
(integer) 1
```

统计操作,比如统计打卡天数:

```bash
127.0.0.1:6379> bitcount sign		# 统计这周的打卡记录,就可以看到是否有全勤~!统计为1的数量
(integer) 3
```



## 4. 事务



提到事务我们就能第一时间想起MySQL的ACID原则!然后还要一句话就是"要么同时成功,要么同时失败!"->原子性!

**注意**:

1. 在Redis中是没有原子性的!Redis单条命令是保证原子性的!但是Redis`事务不保证原子性的`!因为这个所有的命令都是依次执行,相互之间并没有事务!
2. Redis`事务没有隔离级别的概念`,也就是没有脏读幻读等等!
3. 所有的命令在事务中并`没有被直接被执行`,因为首先在入队的时候没有执行,而是在我们发起执行命令的时候才会执行!执行命令Exec

Redis事务本质:一组命令的集合!一个事务中的所有命令都会被序列化,在事务执行过程中会按照顺序执行!

特性:

1. **一次性**:在队列里面一次性执行
2. **顺序性**:会按照顺序依次执行
3. **排他性**：事务在执行过程中不允许别人干扰的!

执行一系列的命令保证我们的命令在事务中安安全全执行完,所以至少需要这三个特性!

```bash
------队列 set set set 执行 ----- 
```

redis事务分三个阶段:

- 开启事务(multi)
- 命令入队(.....)
- 执行事务(exec)

锁:Redis可以实现乐观锁,Redis有个监视器是watch

理解:redis事务就是将一组命令加入到集合中,然后统一依次执行命令!

> 正常执行事务!

```bash
127.0.0.1:6379> multi						# 开启事务
OK
127.0.0.1:6379> set k1 v1					# 添加命令让其入队,添加到队列中
QUEUED			
127.0.0.1:6379> set k2 v2
QUEUED
127.0.0.1:6379> get k2
QUEUED
127.0.0.1:6379> set k3 v3
QUEUED
127.0.0.1:6379> exec						# 执行命令,可以发现入队的时候并没有执行而是到我们执行命令的时候才是真正的执行,这些命令会一个一个依次性执行完的
1) OK
2) OK
3) "v2"
4) OK
```

注意:事务在执行exec命令后就没了就结束了,需要重新开启事务执行

> 放弃事务!

```bash
127.0.0.1:6379> multi					# 开启事务	
OK
127.0.0.1:6379> set k1 v1				# 往队列中添加执行命令
QUEUED
127.0.0.1:6379> set k2 v2
QUEUED
127.0.0.1:6379> set k4 v4
QUEUED
127.0.0.1:6379> discard					# 取消事务,在队列中的所有命令就不会执行
OK
127.0.0.1:6379> get k4					# 取消事务后命令不会执行,所以这里的get是获取不到的!事务队列中命令都不会执行的 
(nil)
```

> 编译型异常(java中是代码有问题,Redis中是命令有错!),事务中所有的命令都不会被执行!

```bash
127.0.0.1:6379> multi															# 开启事务
OK
127.0.0.1:6379> set k1 v2														# 正常往队列中添加命令
QUEUED
127.0.0.1:6379> set k2 v1
QUEUED
127.0.0.1:6379> set k3 v3
QUEUED
127.0.0.1:6379> getset k3														# 错误的命令:这里会抛出异常但是事务还未停止,这里只是给出语法错误的提示
(error) ERR wrong number of arguments for 'getset' command
127.0.0.1:6379> set k4 v4
QUEUED
127.0.0.1:6379> set k5 v5
QUEUED
127.0.0.1:6379> exec												# 执行命令,发现这里报错了,根据提示发现事务被取消,说明只要队列中命令存在语法异常所有命令都不会被执行!
(error) EXECABORT Transaction discarded because of previous errors.
127.0.0.1:6379> get k5												# 所有的命令都不会被执行,所以这里获取是获取不到的!
(nil)
```



> 运行时异常(java中好比是1/0,而在Redis中:如果事务队列中有命令存在语法性错误,那么在执行命令的时候其他命令是可以正常执行的!),所以就没用原子性这个说法!其中错误命令抛出异常!

```bash
127.0.0.1:6379> multi												# 开启事务
OK
127.0.0.1:6379> set k1 v1											# 添加命令
QUEUED
127.0.0.1:6379> incr k1												# 语法没问题,但是在执行的时候由于i++不能对字符串进行自增1的操作,所以会报错!
QUEUED
127.0.0.1:6379> set k2 v2
QUEUED
127.0.0.1:6379> set k3 v3
QUEUED
127.0.0.1:6379> get k3
QUEUED
127.0.0.1:6379> exec												# 执行命令
1) OK
2) (error) ERR value is not an integer or out of range				# 这里给出提示说参数值不是Integer类型范围,这里虽然报错了,但是不影响其他命令
3) OK
4) OK
5) "v3"
127.0.0.1:6379> get k2												# 这里依然是可以获取到的!
"v2"
```

通过这个编译性异常和运行时异常我们可以得出一个概念,这个概念我们在之前就已经提出过:`Redis单条命令是保持原子性的，但是事务不保证原子性`

举个例子:

​	就好比是我们买车,如果是在买车的时候就发生故障,那么我们就会立即找到销车商就不要了因为还没给钱,这个就是编译时异常:检查命令语法错误,整个事务都会被取消了,命令全部取消;而如果我们在购买车后在行驶的过程中出现故障了,那么这个时候我们已经给了钱,经销商就不给退了,所以自己只能将就跑,这个就是运行时异常:在命令执行的时候如果遇到异常事务正常执行,其他命令依旧正常执行;

### 4.1 乐观锁(重要)

悲观锁:

- 很悲观:认为什么时候都会出问题,做事就会很谨慎,做什么事都会加锁!用完才会解锁,这种方式就会很影响效率!

乐观锁:

- 很乐观:认为什么时候都不会出现问题,所以不会上锁,更新数据去判断一下在此期间是否有人修改过数据,通过version字段去比对!比如说在每次去比对的时候先查询出来数据不上锁就把这个version查出来,然后修改的时候就会把这个version带上,判断是否正确,正确才会提交,这就是乐观锁的操作!
- 在MySQL中获取version并不加锁,更新的时候比较version,每次操作都会带上version!

**而在Redis中使用Watch监控-代替使用乐观锁操作**

> Redis监视测试

正常执行成功!没有出现任何问题-乐观锁

```bash
127.0.0.1:6379> set money 100
OK
127.0.0.1:6379> set out 0
OK
127.0.0.1:6379> watch money					# 监视money这个key
OK
127.0.0.1:6379> multi						# 事务正常结束,数据期间没有发生变动,这个时候就正常执行成功!
OK
127.0.0.1:6379> decrby money 20
QUEUED
127.0.0.1:6379> incrby out 20
QUEUED
127.0.0.1:6379> exec						# 事务正常执行监控就会被取消掉
1) (integer) 80
2) (integer) 20
```

测试多线程修改值,使用watch可以当做redis的乐观锁操作,监视失败!

这里我开两个客户端都连一个服务端:

one客户端线程1:

```bash
127.0.0.1:6379> watch money				# 监视money这个对象
OK
127.0.0.1:6379> multi					# 开启事务
OK
127.0.0.1:6379> decrby money 10
QUEUED
127.0.0.1:6379> incrby out 10
QUEUED
127.0.0.1:6379> exec					# 这里在还未执行完事务之前,线程2直接就把money给修改,然后watch监控的money发生了变动就会立即冻结这个对象,然后整个事务就会提交失败
(nil)
127.0.0.1:6379> get money				# 这里就是被线程2给修改了后的值
"1000"
127.0.0.1:6379> get out					# 事务失效,所以这里的值是之前的!
"20"
```

two客户端线程2:

```bash
127.0.0.1:6379> get money				# 获取当前money
"80"
127.0.0.1:6379> set money 1000			# 直接把money进行修改了!
OK
```

**理解**:在线程1中开启对key的watch监控,然后在事务还未提交前,该key被线程2插进来修改了值,那么在线程1中监控的watch就会让该事务提交失败!

回过头来:乐观锁在拿到money的时候就会去获取version,比如是100,然后更新的时候修改为1000,那么这个version就会被修改,然后在事务中执行命令的时候拿到原来的数据去比较就会发生错误!就会提交失败!

如果要对Redis事务加锁就用watch就好了!



如果修改失败,获取最新的值就好

```bash
127.0.0.1:6379> unwatch				# 如果发现事务执行失败,就先解锁
OK
127.0.0.1:6379> watch money			# 获取最新的值,再次监视 select version
OK
127.0.0.1:6379> multi
OK
127.0.0.1:6379> decrby money 1
QUEUED
127.0.0.1:6379> incrby money 1
QUEUED
127.0.0.1:6379> exec				# 比对监视的值是否发生了变化,如果没有发生变化,那么可以执行成功,如果变量就执行失败!
1) (integer) 999
2) (integer) 1000
```



这里记录一下使用使用数据版本（Version）记录机制实现，这是乐观锁最常用的一种实现方式。

​	何谓数据版本？即为数据增加一个版本标识，一般是通过为数据库表增加一个数字类型的 “version” 字段来实现。

在Redis实现乐观锁中使用watch监控每个key都是带有版本号!初始版本号为1;

其他客户端提交数据一次数据库版本号version就进行更新一次，本次事务提交的时候对比版本号（之前提交数据的情况），要是此次版本号低于数据库当前版本号，就会提交失败；

![img](https://gitee.com/miawei/pic-go-img/raw/master/imgs/22a9518f-e355-315f-8d66-d91af4fda723.jpg)

## 5. Jedis

### 5.1 介绍与快速使用

我们之前操作Redis都是通过客户端进行操作,那么这个就是通过Java程序来操作Redis

> 什么是Jedis?

​	是官方推荐的Java连接开发工具!可理解为Java操作Redis的中间件!是一个jar包;如果我们要使用Java操作Redis那么一定要对Jedis很熟悉!

后面用SpringBoot整合的时候直接用xxxTemplates就直接整合使用了,但是我们依然要学习这个,因为我们学习要知其然还要知其所以然!所以我们要从原生JPA看起!

> 测试

1. 导入对应的依赖

   ```xml-dtd
   <!--导入jedis的包-->
   <!-- https://mvnrepository.com/artifact/redis.clients/jedis -->
   <dependency>
       <groupId>redis.clients</groupId>
       <artifactId>jedis</artifactId>
       <version>3.3.0</version>
   </dependency>
   <!--导入阿里巴巴fastjson-->
   <!-- https://mvnrepository.com/artifact/com.alibaba/fastjson -->
   <dependency>
       <groupId>com.alibaba</groupId>
       <artifactId>fastjson</artifactId>
       <version>1.2.75</version>
   </dependency>
   ```

2. 编码测试:

   - 连接数据库
   - 操作命令
   - 断开连接

连接测试:

```java
public class TestPing {
    public static void main(String[] args) {
        // 1.new Jedis对象即可!
        Jedis jedis = new Jedis(new HostAndPort("127.0.0.1",6379));
        // 2.jedis所有的命令就是我们之前学习数据类型哪些基本的命令
        String ping = jedis.ping();
        System.out.println("ping = " + ping);
    }
}
```

输出:

![image-20211013195428497](https://gitee.com/miawei/pic-go-img/raw/master/imgs/image-20211013195428497.png)

### 5.2 常用API

#### 1. 基本命令:

```java
package cn.itesource;

import redis.clients.jedis.HostAndPort;
import redis.clients.jedis.Jedis;

import java.util.Set;

/**
 * @program: Redis-jedis
 * @description:
 * @author: MiaoWei
 * @create: 2021-10-13 19:46
 **/
public class TestPing {
    public static void main(String[] args) {
        Jedis jedis = new Jedis(new HostAndPort("127.0.0.1", 6379));

        System.out.println("清空数据: " + jedis.flushDB());
        System.out.println("判断某个键是否存在: " + jedis.exists("username"));
        System.out.println("新增<'username','MiaoDaWei'>的键值对: " + jedis.set("username", "MiaoDaWei"));
        System.out.println("新增<'password','password'>的键值对: " + jedis.set("password", "password"));
        System.out.println("系统中所有的键如下:  ");
        Set<String> keys = jedis.keys("*");
        System.out.println(keys);
        System.out.println("删除键password: " + jedis.del("password"));
        System.out.println("判断键password是否存在: " + jedis.exists("password"));
        System.out.println("查看键username所存储的值的类型: " + jedis.type("username"));
        System.out.println("随机返回key空间的一个: " + jedis.randomKey());
        System.out.println("重命名key: " + jedis.rename("username", "name"));
        System.out.println("取出改后的name: " + jedis.get("name"));
        System.out.println("按索引选择数据库查询: " + jedis.select(0));
        System.out.println("删除当前选择数据库中的所有key: " + jedis.flushDB());
        System.out.println("返回当前数据库中key的数目: " + jedis.dbSize());
        System.out.println("删除所有数据库中的所有key: " + jedis.flushAll());

    }
}
```

输出:

![image-20211013201637761](https://gitee.com/miawei/pic-go-img/raw/master/imgs/image-20211013201637761.png)

#### 2. String

```java
package cn.itesource;

import redis.clients.jedis.HostAndPort;
import redis.clients.jedis.Jedis;

import java.util.concurrent.TimeUnit;

/**
 * @program: Redis-jedis
 * @description:
 * @author: MiaoWei
 * @create: 2021-10-13 19:46
 **/
public class TestString {
    public static void main(String[] args) {
        Jedis jedis = new Jedis(new HostAndPort("127.0.0.1", 6379));
        jedis.flushDB();

        System.out.println("===================增加数据===================");
        System.out.println(jedis.set("key1", "value1"));
        System.out.println(jedis.set("key2", "value2"));
        System.out.println(jedis.set("key3", "value3"));
        System.out.println("删除键key2: " + jedis.del("key2"));
        System.out.println("获取键key2: " + jedis.get("key2"));
        System.out.println("修改key1: " + jedis.set("key1", "value1Changed"));
        System.out.println("获取key1的值: " + jedis.get("key1"));
        System.out.println("在key3后面加入值: " + jedis.append("key3", "End"));
        System.out.println("key3的值: " + jedis.get("key3"));
        System.out.println("增加多个键值对: " + jedis.mset("key01", "value01", "key02", "value02", "key03", "value03"));
        System.out.println("获取多个键值对: " + jedis.mget("key01", "key02", "key03"));
        System.out.println("获取多个键值对,其中有一项是不存在的: " + jedis.mget("key01", "key02", "key03", "key04"));
        System.out.println("删除多个键值对01与02: " + jedis.del("key01", "key02"));
        System.out.println("获取多个键值对: " + jedis.mget("key01", "key02", "key03"));

        jedis.flushDB();
        System.out.println("===================新增键值对防止覆盖原先值===================");
        System.out.println("不存在key就设置key的value:" + jedis.setnx("key1", "value1")); //可把setnx拆分为 set no :不存在就创建
        System.out.println("不存在key就设置key的value:" + jedis.setnx("key2", "value2"));
        System.out.println("存在key设置value就会失败: " + jedis.setnx("key2", "value2-new"));
        System.out.println("获取key:" + jedis.get("key1"));
        System.out.println("获取key:" + jedis.get("key2"));

        System.out.println("===================新增键值对并设置有效时间===================");
        System.out.println("给key设置有效时间并设置新的value,不管这个key3是否存在: " + jedis.setex("key3", 2, "value3"));	//可把其中的e理解为expire 设置有效时间
        System.out.println("获取这个key3: " + jedis.get("key3"));
        try {
            TimeUnit.SECONDS.sleep(3); //休眠3秒钟
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
        System.out.println("线程休眠3秒钟后获取key3: " + jedis.get("key3"));

        System.out.println("===================获取原值,更新为新值===================");
        System.out.println("获取key2的value并set新的value: " + jedis.getSet("key2", "key2GetSet")); //不管这个key是否存在,都要set新的value,如果存在只是返回之前的value
        System.out.println("获取key2: " + jedis.get("key2"));
        System.out.println("获得key2的值范围内的字串: " + jedis.getrange("key2", 2, 4));
    }
}
```

输出:

![image-20211013205501703](https://gitee.com/miawei/pic-go-img/raw/master/imgs/image-20211013205501703.png)

#### 3. List

```java
package cn.itesource;

import redis.clients.jedis.HostAndPort;
import redis.clients.jedis.Jedis;

/**
 * @program: Redis-jedis
 * @description:
 * @author: MiaoWei
 * @create: 2021-10-13 19:46
 **/
public class TestList {
    public static void main(String[] args) {
        Jedis jedis = new Jedis(new HostAndPort("127.0.0.1", 6379));
        jedis.flushDB();

        System.out.println("================添加一个list================");
        jedis.lpush("collections", "ArrayList", "Vector", "Stack", "HashMap", "WeakHashMap", "LinkedHashMap");
        jedis.lpush("collections", "HashSet");//lpush可理解为以左边为中心,往左添加,然后后续添加将前面的往后移,后续放在前面的位置
        jedis.lpush("collections", "TreeSet");
        jedis.lpush("collections", "TreeMap");
        System.out.println("collections的内容: " + jedis.lrange("collections", 0, -1)); //-1代表倒数第一个元素,-2代表倒数第二个元素
        System.out.println("collections区间0-3的内容: " + jedis.lrange("collections", 0, 3)); //-1代表倒数第一个元素,-2代表倒数第二个元素
        System.out.println("================================");
        //删除列表指定的值,第二个参数为删除的个数(有重复时),后add进去的值先被删除,这类似于出栈
        System.out.println("删除指定元素的个数: " + jedis.lrem("collections", 2, "HashMap"));
        System.out.println("collections的内容: " + jedis.lrange("collections", 0, -1));
        System.out.println("删除下标0-3区间之外的元素: " + jedis.ltrim("collections", 0, 3));
        System.out.println("collections的内容: " + jedis.lrange("collections", 0, -1));
        System.out.println("collections列表出栈(左端): " + jedis.lpop("collections"));
        System.out.println("collections的内容: " + jedis.lrange("collections", 0, -1));
        System.out.println("collections添加元素,从列表右端,与lpush相对应: " + jedis.rpush("collections", "EnumMap"));
        System.out.println("collections的内容: " + jedis.lrange("collections", 0, -1));
        System.out.println("collections列表出栈(右端): " + jedis.rpop("collections"));
        System.out.println("collections的内容: " + jedis.lrange("collections", 0, -1));
        System.out.println("修改指定collections指定下标1的内容: " + jedis.lset("collections", 1, "LinkedArrayList"));
        System.out.println("collections的内容: " + jedis.lrange("collections", 0, -1));
        System.out.println("=========================================");
        System.out.println("collections的长度: " + jedis.llen("collections"));
        System.out.println("获取collections下标为2的元素: " + jedis.lindex("collections", 2));
        System.out.println("=========================================");
        jedis.lpush("sortedList", "3", "6", "2", "0", "7", "4");
        System.out.println("sortedList排序前: " + jedis.lrange("sortedList", 0, -1));
        System.out.println(jedis.sort("sortedList"));
        System.out.println("sortedList排序后: " + jedis.lrange("sortedList", 0, -1));

    }
}
```

输出:

![image-20211013213318116](https://gitee.com/miawei/pic-go-img/raw/master/imgs/image-20211013213318116.png)

#### 4. Set

```java
package cn.itesource;

import redis.clients.jedis.HostAndPort;
import redis.clients.jedis.Jedis;

/**
 * @program: Redis-jedis
 * @description:
 * @author: MiaoWei
 * @create: 2021-10-13 19:46
 **/
public class TestSet {
    public static void main(String[] args) {
        Jedis jedis = new Jedis(new HostAndPort("127.0.0.1", 6379));
        jedis.flushDB();

        System.out.println("=======================向集合中添加元素(不重复)========================");
        System.out.println(jedis.sadd("eleSet", "e1", "e2", "e3", "e4", "e5"));
        System.out.println(jedis.sadd("eleSet", "e6"));
        System.out.println(jedis.sadd("eleSet", "e6"));
        System.out.println("eleSet的所有元素为: " + jedis.smembers("eleSet"));
        System.out.println("删除一个元素e0: " + jedis.srem("eleSet", "e0"));
        System.out.println("eleSet的所有元素为: " + jedis.smembers("eleSet"));
        System.out.println("删除两个元素e7和e6: " + jedis.srem("eleSet", "e7", "e6"));
        System.out.println("eleSet的所有元素为: " + jedis.smembers("eleSet"));
        System.out.println("随机的移除集合中的一个元素: " + jedis.spop("eleSet"));
        System.out.println("随机的移除集合中的一个元素: " + jedis.spop("eleSet"));
        System.out.println("eleSet的所有元素为: " + jedis.smembers("eleSet"));
        System.out.println("eleSet中包含元素的个数为: " + jedis.scard("eleSet"));
        System.out.println("e3是否在eleSet中: " + jedis.sismember("eleSet", "e3"));
        System.out.println("e1是否在eleSet中: " + jedis.sismember("eleSet", "e1"));
        System.out.println("e5是否在eleSet中: " + jedis.sismember("eleSet", "e5"));
        System.out.println("=======================================================");
        System.out.println(jedis.sadd("eleSet1", "e1", "e2", "e4", "e3", "e0", "e8", "e7", "e5"));
        System.out.println(jedis.sadd("eleSet2", "e1", "e2", "e4", "e3", "e0", "e8"));
        System.out.println("将eleSet1中删除e1并存入eleSet3中: " + jedis.smove("eleSet1", "eleSet3", "e1"));
        System.out.println("将eleSet1中删除e2并存入eleSet3中: " + jedis.smove("eleSet1", "eleSet3", "e2"));
        System.out.println("eleSet1中的元素: " + jedis.smembers("eleSet1"));
        System.out.println("eleSet3中的元素: " + jedis.smembers("eleSet3"));
        System.out.println("=================集合运算==============================");
        System.out.println("eleSet1中的元素: " + jedis.smembers("eleSet1"));
        System.out.println("eleSet2中的元素: " + jedis.smembers("eleSet2"));
        System.out.println("eleSet1和eleSet2的交集: " + jedis.sinter("eleSet1", "eleSet2"));
        System.out.println("eleSet1和eleSet2的并集: " + jedis.sunion("eleSet1", "eleSet2"));
        System.out.println("eleSet1和eleSet2的差集: " + jedis.sdiff("eleSet1", "eleSet2")); //eleSet1中有,eleSet2中没有
        jedis.sinterstore("eleSet4", "eleSet1", "eleSet2"); //求交集并将交集保存到dstkey集合
        System.out.println("eleSet4中的元素: " + jedis.smembers("eleSet4"));
    }
}
```

输出:

![image-20211014182406100](https://gitee.com/miawei/pic-go-img/raw/master/imgs/image-20211014182406100.png)

#### 5.Hash

```java
package cn.itesource;

import redis.clients.jedis.Jedis;

import java.util.HashMap;
import java.util.Map;

public class TestHash {
    public static void main(String[] args) {
        Jedis jedis = new Jedis("127.0.0.1", 6379);
        jedis.flushDB();
        Map<String, String> map = new HashMap<String, String>();
        map.put("key1", "value1");
        map.put("key2", "value2");
        map.put("key3", "value3");
        map.put("key4", "value4");
        map.put("key4", "value4"); //不能重复
        //添加名称为hash（key）的hash元素
        jedis.hmset("hash", map); // 批量设置
        //向名称为hash的hash中添加key为key5，value为value5元素
        jedis.hset("hash", "key5", "value5");
        System.out.println("散列hash的所有键值对为：" + jedis.hgetAll("hash"));//return Map<String,String>
        System.out.println("散列hash的所有键为：" + jedis.hkeys("hash"));//return Set<String>
        System.out.println("散列hash的所有值为：" + jedis.hvals("hash"));//return List<String>
        System.out.println("将key6保存的值加上一个整数，如果key6不存在则添加key6：" + jedis.hincrBy("hash", "key6", 6));
        System.out.println("散列hash的所有键值对为：" + jedis.hgetAll("hash"));
        System.out.println("将key6保存的值加上一个整数，如果key6不存在则添加key6：" + jedis.hincrBy("hash", "key6", 3));
        System.out.println("散列hash的所有键值对为：" + jedis.hgetAll("hash"));
        System.out.println("删除一个或者多个键值对：" + jedis.hdel("hash", "key2"));
        System.out.println("散列hash的所有键值对为：" + jedis.hgetAll("hash"));
        System.out.println("散列hash中键值对的个数：" + jedis.hlen("hash"));
        System.out.println("判断hash中是否存在key2：" + jedis.hexists("hash", "key2"));
        System.out.println("判断hash中是否存在key3：" + jedis.hexists("hash", "key3"));
        System.out.println("获取hash中的值：" + jedis.hmget("hash", "key3"));
        System.out.println("获取hash中的值：" + jedis.hmget("hash", "key3", "key4"));
    }
}
```

输出:

![image-20211014183220178](https://gitee.com/miawei/pic-go-img/raw/master/imgs/image-20211014183220178.png)

#### 6. Zset与其他特殊类型

这里我就不贴代码了,直接看吧是不是都有对应的API:

Zset:

![image-20211014183829980](https://gitee.com/miawei/pic-go-img/raw/master/imgs/image-20211014183829980.png)

geo:

![image-20211014183852518](https://gitee.com/miawei/pic-go-img/raw/master/imgs/image-20211014183852518.png)

Hyperloglog:

![image-20211014183934459](https://gitee.com/miawei/pic-go-img/raw/master/imgs/image-20211014183934459.png)

Bitmap:

![image-20211014184015586](https://gitee.com/miawei/pic-go-img/raw/master/imgs/image-20211014184015586.png)

> 通过这个我们可以发现:这里的API跟我们之前敲的命令一模一样!甚至可以说照搬过去了,所以我们学了命令再去看这个就一目了然了!

#### 7.事务

这是正常执行的:

```java
public static void main(String[] args) {
        Jedis jedis = new Jedis(new HostAndPort("127.0.0.1", 6379));

        JSONObject jsonObject = new JSONObject();
        jsonObject.put("hello", "world");
        jsonObject.put("hello1", "world1");
        String jsonString = jsonObject.toJSONString();
        //开启事务
        Transaction transaction = jedis.multi();

        try {
            transaction.set("user1", jsonString);
            transaction.set("user2", jsonString);

            transaction.exec(); //执行事务
        } catch (Exception e) {
            transaction.discard(); //放弃事务
            e.printStackTrace();
        } finally {
            System.out.println(jedis.get("user1"));
            System.out.println(jedis.get("user2"));
            //关闭连接
            jedis.close();
        }
    }
```

输出:

![image-20211014185419371](https://gitee.com/miawei/pic-go-img/raw/master/imgs/image-20211014185419371.png)

这是发生编译时异常:

```java
package cn.itesource.Transaction;

import com.alibaba.fastjson.JSONObject;
import redis.clients.jedis.HostAndPort;
import redis.clients.jedis.Jedis;
import redis.clients.jedis.Transaction;

/**
 * @program: Redis-jedis
 * @description:
 * @author: MiaoWei
 * @create: 2021-10-14 18:43
 **/
public class TestTx {
    public static void main(String[] args) {
        Jedis jedis = new Jedis(new HostAndPort("127.0.0.1", 6379));
        jedis.flushDB(); //防止上一次的数据保存
        JSONObject jsonObject = new JSONObject();
        jsonObject.put("hello", "world");
        jsonObject.put("hello1", "world1");
        String jsonString = jsonObject.toJSONString();
        //开启事务
        Transaction transaction = jedis.multi();
        try {
            transaction.set("user1", jsonString);
            transaction.set("user2", jsonString);
            int i = 1 / 0;  //代码执行失败,抛出异常,事务执行失败!
            transaction.exec(); //执行事务
        } catch (Exception e) {
            transaction.discard(); //放弃事务
            e.printStackTrace();
        } finally {
            System.out.println(jedis.get("user1"));
            System.out.println(jedis.get("user2"));
            //关闭连接
            jedis.close();
        }
    }
}
```

输出:

![image-20211014185813550](https://gitee.com/miawei/pic-go-img/raw/master/imgs/image-20211014185813550.png)

可以发现一旦编译时发生异常,抛出了异常那么,整个事务都会被取消执行失败!

而我们后面实现乐观锁也是一样的,我们只需要加一个`jedis.watch(xxx)`即可!

## 6.Redis.config

这里是介绍Redis在启动的时候是如何进行启动的,而通过它的配置文件,我们来了解一下具体的使用:

我们学东西,如果你只会上面的那些基本的东西,那么你压根不能懂Redis!而这配置文件里的东西才是我们需要去了解的!通过这个配置文件我们就能redis几乎所有的功能!

我们打开Redis所在的目录下的配置文件,比如我这里的是`redis.windows.conf`打开进行解析:

> 单位:

```properties
# Redis configuration file example

# Note on units: when memory size is needed, it is possible to specify
# it in the usual form of 1k 5GB 4M and so forth:
# 这里是默认的一些单位设置!
# 1k => 1000 bytes
# 1kb => 1024 bytes
# 1m => 1000000 bytes
# 1mb => 1024*1024 bytes
# 1g => 1000000000 bytes
# 1gb => 1024*1024*1024 bytes
#
# units are case insensitive so 1GB 1Gb 1gB are all the same. 这里翻译:这里对大小写不敏感,也就是说你可以写1GB,也可以写1gb....
这里是Redis的默认的一些配置,
################################## INCLUDES ###################################
```

1. 配置文件unit单位,对大小写不敏感

> 包含:

```properties
################################## INCLUDES ###################################

# Include one or more other config files here.  This is useful if you
# have a standard template that goes to all Redis servers but also need
# to customize a few per-server settings.  Include files can include
# other files, so use this wisely.
#
# Notice option "include" won't be rewritten by command "CONFIG REWRITE"
# from admin or Redis Sentinel. Since Redis always uses the last processed
# line as value of a configuration directive, you'd better put includes
# at the beginning of this file to avoid overwriting config change at runtime.
#
# If instead you are interested in using includes to override configuration
# options, it is better to use include as the last line.
#
# include .\path\to\local.conf
# include c:\path\to\other.conf
```

就是好比我们学习Spring的时候import,或者JSP中的include,这里意思就是可以把多个配置文件都配置过来!

> 网络:

```bash
################################## NETWORK #####################################
# ... 这里我省略其他,直接看核心
bind 127.0.0.1		//绑定的ip
protected-mode yes  //表示是否是受保护的模式,一般都是开启的,保证安全性的!
port 6379			//绑定的端口 
```

> 通用配置:

```bash
################################# GENERAL #####################################
# ... 这里我省略其他,直接看核心
daemonize yes    # 表示是否以守护进程开启,默认为no,我们需要自己开启为yes!就是退出还在后台运行!
supervised no	 # 这个就是管理守护线程的,不用去动
pidfile /var/run/redis.pid # 如果以后台的方式运行,我们就需要指定一个pid文件!

# 日志
# Specify the server verbosity level.
# This can be one of:
# debug (a lot of information, useful for development/testing)  //这里位debug,一般用于测试和开发阶段!
# verbose (many rarely useful info, but not a mess like the debug level) //这里就是记录较多的日志信息.一般不用去看
# notice (moderately verbose, what you want in production probably)	//通知,部分的重要的日志信息.仅使用与生产环境使用!
# warning (only very important / critical messages are logged)	//警告信息.关键的信息!
loglevel notice
logfile ""  # 日志的文件位置名,如果为空,那么就标准的输出了!
databases 16  # 数据库数量,默认的是16个数据库
always-show-Logo yes  # 是否显示这个logo,就是我们开启Redis服务的时候显示的那个logo
```

> 快照(后面持久化会用到,就是在规定的时间内,执行了多少次操作,则会持久化到文件 .rdb aof):

```bash
################################ SNAPSHOTTING  ################################
# save: 在当下执行了多少时间怎样去保存这个规则->这是个持久化规则
# Redis是一个内存式数据库,如果不持久化的话就会丢失数据,因为内存是断电即失!
save 900 1 		# 如果900秒内也就是15分钟,如果至少一个key进行了修改,那么这个时候我们就进行持久化操作!
save 300 10		# 假设300秒内,至少10个key进行修改,那么这个时候我们就进行持久化操作!
save 60 10000	# 假设60秒内,至少10000个key被进行修改,那么就会执行持久化操作,这种就是高并发的情况下!

stop-writes-on-bgsave-error yes  	# 如果持久化的时候出现错误,是否还继续工作,默认是开启
rdbcompression yes					# 是否压缩我们的rdb文件,默认是开启,压缩的话就会消耗一些CPU资源,而rdb文件就是持久化的文件
rdbchecksum yes						# 在保存rdb文件的时候,就会去校验我们的rdb文件,如果出错了自动去做一些操作修复!
dir ./								# rdb文件保存的目录!
```

> 安全

```bash
################################## SECURITY ###################################
requirepass 123456		# 设置redis密码,默认是为空,一般我们推荐使用命令行设置命令
```

密码的话我们也可以进行设置,当然默认为空,那我们在cmd中查看用户密码那如何查看呢?

```bash
127.0.0.1:6379> config get requirepass					# 获取redis密码
1) "requirepass"
2) ""
127.0.0.1:6379> config set requirepass "123456"			# 设置redis密码
OK
127.0.0.1:6379> config get requirepass					# 设置后我们就能看到必须要登录,否则就没用权限,不然我们所有的命令都无法使用!
(error) NOAUTH Authentication required.
127.0.0.1:6379>  config get requirepass
(error) NOAUTH Authentication required.
127.0.0.1:6379> ping
(error) NOAUTH Authentication required.					# 验证密码
127.0.0.1:6379> auth 123456
OK
127.0.0.1:6379>  config get requirepass					# 获取密码就可以看到了!
1) "requirepass"
2) "123456"
```

> 客户端限制

```bash
################################### LIMITS ####################################

# Set the max number of connected clients at the same time. By default
# this limit is set to 10000 clients, however if the Redis server is not
# able to configure the process file limit to allow for the specified limit
# the max number of allowed clients is set to the current file limit
# minus 32 (as Redis reserves a few file descriptors for internal uses).
#
# Once the limit is reached Redis will close all the new connections sending
# an error 'max number of clients reached'.
#
# maxclients 10000
```

