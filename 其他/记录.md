# 笔记

## 1. 数据库三范式

范式就是规范，就是要遵守的原则。一般要遵守有三种范式

1. 1NF(1范式): 设计数据库表的列的时候，这些列不可拆分。 列的`原子性`，其实这种范式可以不用管，关系型数据库默认都满足
2. 2NF(2范式)：表中行是`唯一`，通常设计一个主键来实现
3. 3NF(3范式)： 如果一张表的数据能够通过其他表推导出来，不应该单独设计，通过外键的方式`关联查询`出来

**注意**:反3NF：正常情况来说，我们必须遵循3NF，但是有的时候我们为了增强查询效率，会设计一些冗余字段，变多表查询为单表查询。

**理解**:1范式就是说列具有原子性不能拆分了,比如状态0和1就不能再拆分了;2范式指一张表中两行数据不能完全重复;3范式说如果一张表的数据能够通过其他表得出那么此时就要通过关联来获取,对字段的冗余部分进行剔除!

## 2. 短信验证码发送流程

![image-20211030093112116](https://gitee.com/miawei/pic-go-img/raw/master/imgs/image-20211030093112116.png)

​	**流程**:用户发送验证码,首先从通过手机号和业务绑定一个key,然后从Redis缓存中获取,如果获取到那么此时我们就对value进行拆分,获取我们设置的时间戳,然后我们就判断这个时间戳跟当前时间戳是否相差1分钟,也就是说判断用户是否存在1分钟内连续发送,如果存在连续发送那么就抛出异常非法信息,如果超过一分钟,那么并且此时我们是可以获取到的,那么就说明是在3分钟之内的,可能因为网络延迟等原因用户没有及时的收到短信,所以避免重复发送造成验证码不一致,所以这里就直接重置验证码的时间为3分钟,注意此时的value的时间戳也要得到更新,因为如果不更新下一次用户又重发那么获取value很明显已经过来时间戳那么又要重置3分钟;下一步告知用户验证码已发送,然后回到我们刚刚那个点如果在Redis获取验证码不存在那么就直接发送验证码然后存于Redis缓存,注意要先执行发送再执行放入缓存中,因为可能出现手机号发送失败,而造成验证码存于缓存中!

```bash
1.校验
 1.1 手机号不能为空
 1.2 手机号是否被注册 查询t_user表
2.判断验证码是否有效（3分钟），从redis中是否能拿到 key： business_register:15982495855
 2.1 如果拿到了 需要判断是否过了1分钟重发时间      value:  9527:14679321341313
  2.1.1 如果没有过重发时间,报错：请勿重发获取验证码  1*60*1000
  2.1.2 如果过了，使用上次的验证码====
 2.2 如果拿不到
  2.2.1 直接生成新的验证码  ===
3.存储redis 设置3分钟过期
4.发送短信通知客人 验证码是：9527 请在3分钟内使用
```

注:如果说用户在1分钟之后重新发送验证码,那么这里还有另一种想法,比如可以重新发送验证码然后替换之前在redis中的验证码,但是这样就会造成一个问题,用户就会收到两次验证码,不过后台存储的是最新的那个!而一旦替换存储在redis服务器中那么时效重置为3分钟!

## 3. 短信接口

短信验证，只有三大运营商具有短信发送的能力。要发送短信只有找三大运营，或者中间商。简单说就是要找第三方的短信平台。常见的有阿里云，京东智联云，乐讯通等等非常多,

我们项目中使用网建短信通：http://sms.webchinese.com.cn/Rates.shtml

注册以后查看API接口:

![image-20211030094516079](https://gitee.com/miawei/pic-go-img/raw/master/imgs/image-20211030094516079.png)

![image-20211030094527470](https://gitee.com/miawei/pic-go-img/raw/master/imgs/image-20211030094527470.png)

测试:

```xml-dtd
<!-- https://mvnrepository.com/artifact/commons-httpclient/commons-httpclient -->
<dependency>
    <groupId>commons-httpclient</groupId>
    <artifactId>commons-httpclient</artifactId>
    <version>3.1</version>
</dependency>
```

```java
package cn.itsource.basic.util;

/**
 * 短信常量类
 */
public class SmsContants {

    //用户名
    public static final String UID = "xxx";
    //秘钥
    public static final String KEY = "yyyy";

}

package cn.itsource.basic.util;

import org.apache.commons.httpclient.Header;
import org.apache.commons.httpclient.HttpClient;
import org.apache.commons.httpclient.NameValuePair;
import org.apache.commons.httpclient.methods.PostMethod;

/**
 * 短信发送工具类
 */
public class SmsUtil {

    /**
     * 发送短信
     * @param phones 手机们 a,b
     * @param content 发送内容
     * @return 返回值
     */
    public static String  sendSms(String phones,String content){
        PostMethod post = null;
        try {
            HttpClient client = new HttpClient();
            post = new PostMethod("http://utf8.api.smschinese.cn");
            post.addRequestHeader("Content-Type","application/x-www-form-urlencoded;charset=utf8");//在头文件中设置转码
            NameValuePair[] data ={ new NameValuePair("Uid", SmsContants.UID),
                    new NameValuePair("Key", SmsContants.KEY),
                    new NameValuePair("smsMob",phones),
                    new NameValuePair("smsText",content)};
            post.setRequestBody(data);

            client.executeMethod(post);
            int statusCode = post.getStatusCode();
            System.out.println("statusCode:"+statusCode); //200 404 400
            String result = new String(post.getResponseBodyAsString().getBytes("utf8"));
            return result;

        } catch (Exception e) {
            e.printStackTrace();
        }
        finally {
            if (post != null) {

                post.releaseConnection();
            }
        }
        return null;
    }

    public static void main(String[] args) {
        System.out.println(SmsUtil
                .sendSms("13330964748", "您的验证码为：8848"));
    }
}
```

> 其实发短信流程不复杂,第一步:通过点击链接进行注册,第二步通过注册我们有5条免费的短信和一个APIKey,第三步:根据官方示例copy过来进行修改,就可以发送!

## 4.token

**引入**:我们思考一下之前有状态的登录方案是什么?

`session`-登录之后要把登录状态保持下来,就用到tomcat的会话跟踪技术;

session往往跟Cokkie一起搭配使用,比较依赖于cookie里面的jessionid;

![image-20211101144519464](https://gitee.com/miawei/pic-go-img/raw/master/imgs/image-20211101144519464.png)

**理解**:用户访问网站,如果是第一次登录那么就会创建一个cookie并将服务器创建好的session信息通过一个jessionid进行写入并进行保存到客户端的浏览器总,下一次访问的时候就可以携带cookie中的jessionID到服务器端查找session进而判断是否存在或有效,来决定是否登录!

**注意:**cookie是服务器端创建然后保存到浏览器的,session是一种会话技术!

**缺点:**

1. 随着项目不断演进,存放在服务器端的session就会变得庞大,占用一定的资源,服务器性能降低
2. cookie+session不支持APP环境,因为APP里面压根就没有cookie
3. cookie是存储在客户端,安全性较低,若清除cookie那么登录信息也就没有了!

> 解决方案:无状态方案-token方案

这是一种完全抛弃了session的方案,我们可以使用redis缓存机制来实现这个方案,因为redis缓存是一款高性能、高可用的缓存中间件!

**流程:**token其实就是由UUID进行生成的字符串,我们通常设置30分钟就到期来保持用户的登录信息,然后前端每次发起请求都带上token,后端拦截器进行判断是否存在token

这种方案与session方案的**好处**就在于:session是存放在服务器端,会造成服务器内存资源的占用较大,效率较低,影响服务器性能!而token使用的字符串的形式在单独的服务中进行存储,这种不仅提高了效率并且后面项目分裂为分布式集群的形式那么这种方案依然有效!而session的话就会变得不太友好!

### 4.1 浏览器存储技术

之前我们都知道浏览器进行存储的有`Cookie`;

**好处:**设置有效期,降低服务器压力

**缺点:**有大小限制,并且是存储在客户端不安全!

其实还有另外两种存储技术:`sessionStorage`和`localStorage`

sessionStorage:存放的数据只在当前窗口有效

localStorage:持久化存储。只要不删除，在当前浏览器永远有效

这是DEMO代码:

```html
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Title</title>
    <script type="text/javascript">
        //sessionStorage 会话存储，当前窗口有效
        //localStorage 持久化存储，永远有效，只要不删除
        // function add() {
        //
        //     sessionStorage.setItem("user","{'name':'zs','age':18}")
        // }
        // function del() {
        //     sessionStorage.removeItem("user")
        // }
        // function update() {
        //     sessionStorage.setItem("user","{'name':'ls','age':18}")
        // }
        // function get() {
        //     alert(sessionStorage.getItem("user"));
        // }
        function add() {

            localStorage.setItem("user","{'name':'zs','age':18}")
        }
        function del() {
            localStorage.removeItem("user")
        }
        function update() {
            localStorage.setItem("user","{'name':'ls','age':18}")
        }
        function get() {
            alert(localStorage.getItem("user"));
        }
    </script>
</head>
<body>
  <input type="button" value="add" onclick="add()">
  <input type="button" value="del" onclick="del()">
  <input type="button" value="update" onclick="update()">
  <input type="button" value="get" onclick="get()">

</body>
</html>
```

客户端在这里:

![image-20211101151810061](https://gitee.com/miawei/pic-go-img/raw/master/imgs/image-20211101151810061.png)



**注意:**

1. sessionStorage只是在单个网页窗口有效,一旦关闭则自动清除
2. LocalStoage是存储在浏览器本地,也就是换个窗口都是依然存在的,浏览器关闭然后再打开也是存在的!

3. 以上两种存储都是基于当前网站存储,所以可以看见对应的地址,如果换个网站比如现在打开京东网页,那么我们在当前项目保存的信息就不存在!

### 4.2 拦截器

怎么让token每次都携带过去:

1）登录成功后把token存放到浏览器，如果是移动端写文件。  localStorage

2）每次对后端的请求，都从浏览器获取token并且携带过去,对后端请求都是使用axios，使用axios前置拦截器给请求追加一个请求头

**核心:**其拦截器的核心,后端:一个拦截器获取token进行判断是否有效,前端三个拦截器:前置、后置、静态资源拦截器;

这里直接贴代码:

后端:

```java
@Configuration
public class WebConfigurer implements WebMvcConfigurer {
    @Autowired
    private LoginInterceptor loginInterceptor;
    /**
     * 添加拦截器
     *
     * @param registry 注册表
     */
    @Override
    public void addInterceptors(InterceptorRegistry registry) {
        registry.addInterceptor(loginInterceptor)
                //拦截所有请求
                .addPathPatterns("/**")
                //放行地址
                    //文件上传
                .excludePathPatterns("/fastDfs/**")
                    //用户门户网站端发起验证码、注册、登录
                .excludePathPatterns("/user/**")
                    //管理端店铺入驻、管理员登录
                .excludePathPatterns("/shop/**");
    }
}
@Component
public class LoginInterceptor implements HandlerInterceptor {
    @Autowired
    private RedisUtil redisUtil;
    @Override
    public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception {
        //获取前端请求中携带的token
        String token = request.getHeader("token");
        //为空则拦截,不为空则判断是否存在token
        if (CharSequenceUtil.isNotEmpty(token)) {
            //从缓存中是否能拿得到
            Object isExist = redisUtil.get(token);
            if (!Objects.isNull(isExist)) {
                //如果缓存中存在那么此时就重置失效时间
                redisUtil.expire(token, 60 * 30);
                return true;
            }
        }
        // TODO: 2021/10/30 拦截做处理
        throw new AccountExpiredException("您当前账户已过期,请重新登录!");
    }
}
```

前端:

```javascript
//前置拦截器,每次发起请求都会首先从这里开始拦截
//为了后端校验是否已经登录，只要用axios的请求都要携带token
//这个算前置拦截器
axios.interceptors.request.use(config => {
    //从本地存储空间获取这个token然后添加到请求中的headers里面给后端!
    let token = localStorage.getItem("token");
    if (token) {
        config.headers["token"] = token;  
    }
    return config;
}, error => {
    Promise.reject(error)
});

//这个是前端后置拦截器,在获取每一个请求的响应走这个拦截器
axios.interceptors.response.use(config=>{
    //如果在前置拦截器中没有token,后端就会拦截并返回这个状态
    if (config.data.code === 403) {
        localStorage.removeItem("token");
        localStorage.removeItem("logininfo");
        //跳转到指定路径path
        router.push({ path: '/login' });
    }
    return config;
},error => {
    Promise.reject(error)
})

// 静态资源拦截器,拦截页面请求path比如登录或者店铺注册就不拦截,其他访问静态资源如:path判断是不是有token,有则不拦截
//对页面跳转进行拦截!
router.beforeEach((to, from, next) => {
  //NProgress.start();
  if (to.path === '/login' || to.path==='/shopRegister') {
    localStorage.removeItem("token");
    localStorage.removeItem("logininfo");
    next(); //放行
    return; //不往下执行

  }
  let user = JSON.parse(localStorage.getItem('logininfo'));
  if (!user) {
    next({ path: '/login' })
  } else {
    next()
  }
})
```

> 拦截器的话也不复杂,就是每次请求前和响应后进行一个拦截,然后进行相应的处理!

访问资源流程分析:

![image-20211101152835590](https://gitee.com/miawei/pic-go-img/raw/master/imgs/image-20211101152835590.png)

**理解**:用户请求axios异步请求,首先会经过前置拦截器,从本地存储技术中拿取token并设置到请求头信息中,然后请求到后端,此时后端就有一个后端拦截器,会对请求信息中的token判断是否能从redis中获取到,如果可以拿到那么设置刷新过期时间30分钟,并放行请求,如果获取不到那么就直接拦截下来并返回给前端报没有权限的异常信息,然后前端返回请求就会经过一个后置拦截器,分析返回的请求中是否是后端拦截报的异常,如果是那么就定位跳转到指定登录界面,如果不是照常放行!

## 5.Saas平台设计

SaaS提供商为企业搭建信息化所需要的所有网络基础设施及软件、硬件运作平台，并负责所有前期的实施、后期的维护等一系列服务，企业无需购买软硬件、建设机房、招聘IT人员，即可通过互联网使用信息系统。就像打开自来水龙头就能用水一样，企业根据实际需要，从SaaS提供商租赁软件服务。

![image-20211125111234693](https://gitee.com/miawei/pic-go-img/raw/master/imgs/image-20211125111234693.png)

传统软件模式:

开发公司开发的产品给客户安装, 然后客户需要自己安装服务器等等, 如果有问题那么就需要开发公司去专门派发人员去维护!

缺点:人员成本高!维护麻烦!



SaaS模式带来的问题：

1. 软件面向的是多个客户企业的数据,数据量变大，比如达到上百万，千万数据：考虑做集群，分库，分表

2. 不同客户企业的数据如何隔离

3. 不同客户企业权限如何处理：需要考虑企业，套餐，角色，权限，资源

### 5.1 Saas平台数据隔离

```
如何把不同的公司做数据库区分?
```

1. 独立数据库

   即一个租户一个数据库，这种方案的用户数据隔离级别最高，安全性最好，但成本较高

   1. 优点
      为不同的租户提供独立的数据库，有助于简化数据模型的扩展设计，满足不同租户的独特需求；如果出现故障，恢复数据比较简单。

   2. 缺点
      增多了数据库的安装数量，随之带来维护成本和购置成本的增加。
      这种方案与传统的一个客户、一套数据、一套部署类似，差别只在于软件统一部署在运营商那里。如果面对的是银行、医院等需要非常高数据隔离级别的租户，可以选择这种模式，提高租用的定价。如果定价较低，产品走低价路线，这种方案一般对运营商来说是无法承受的。

   ![image-20211125111656133](https://gitee.com/miawei/pic-go-img/raw/master/imgs/image-20211125111656133.png)

2. 共享数据库,隔离数据库架构

   这是第二种方案，即多个或所有租户共享Database，但是每个租户一个Schema（也可叫做一个user）。

      通过Schema做区分user
   
   1. 优点
      为安全性要求较高的租户提供了一定程度的逻辑数据隔离，并不是完全隔离；每个数据库可支持更多的租户数量。
   
   2. 缺点
      如果出现故障，数据恢复比较困难，因为恢复数据库将牵涉到其他租户的数据；
      如果需要跨租户统计数据，存在一定困难。
   
   ![image-20211125111739901](https://gitee.com/miawei/pic-go-img/raw/master/imgs/image-20211125111739901.png)

3.共享数据库，共享数据架构，使用外键区分数据

​	这是第三种方案，即租户共享同一个Database、同一个Schema，共享表，但在表中增加TenantID多租户的数据字段。这是共享程度最高、隔离级别最低的模式。

用外键区分数据库,都在一个数据库通过不同的表的外键来关联查找属于客户自己的数据;缺点：数据隔离不是很彻底

	1. 优点
		三种方案比较，第三种方案的维护和购置成本最低，允许每个数据库支持的租户数量最多。

2. 缺点：
   隔离级别最低，安全性最低，需要在设计开发时加大对安全的开发量；
   数据备份和恢复最困难，需要逐表逐条备份和还原。
   如果希望以最少的服务器为最多的租户提供服务，并且租户接受牺牲隔离级别换取降低成本，这种方案最适合。

![image-20211125111923006](https://gitee.com/miawei/pic-go-img/raw/master/imgs/image-20211125111923006.png)

查询不同的租户的数据的时候，需要增加条件：where tenant_id = 登录的租户ID



4. 共亨数据库，共亨数据架构，不同的机构使用不同的表

   不同的机构使用不同的表,表使用后缀进行区分如：t_employee_ali ， t_employee_tx

   ![image-20211125111957356](https://gitee.com/miawei/pic-go-img/raw/master/imgs/image-20211125111957356.png)

   使用mybatis拦截器来修改表名,   好处: 用占位符来替换表名 但是这样呢表也会随之增多

## 6.优化的方案

**从后端角度来说**:
	1. 查询较多可以做redis
		1.1 实时性要求不高:可以写一个定时任务如:一个小时就从数据库查询然后更新redis,而前端查询就可以直接从redis查询即可!
		1.2 实时性要求高:保证redis和数据库的一致性那么可以使用某些框架去监听数据库日志文件的变化然后去更新redis,从而达到数据的一致性!或者每次修改数据库就立即删除、更新缓存！
	2.如果前端发起一个请求,在这一个请求里要查询各种数据然后综合返回给前端,那么这种我们就可以使用jdk1.8新特性新开一个线程,达到一个异步的作用,然后最终合并在一起再返回给客户端,如实现Callable接口

**从前端角度来说**:

1. 我们可以使用js压缩技术将js进行压缩,然后从后台服务中返回!这样就减少网络传输中静态资源大小
2. 由于每次加载前端都是首先从后台获取js等然后加载到前端页面,然后再发送异步请求到后台服务,那么这种呢我们可以把静态资源：html,js,css部署到Nginx , 减轻后台服务的压力，实现动静分离
3.当然每次都从Nginx中获取静态资源也是属于一种网络开销的一种方式,而用户在不同地区访问这个页面那么就会在网络上走各种网络服务商到达Nginx然后返回,这样的方式比较缓慢,所以可以把静态资源放到专门的CDN缓存服务器，浏览器直接从CDN获取静态资源 ， CDN可以根据地区就近选择
4. 还有一种方式就是将请求的数据渲染到一个HTML模板上,然后每次请求都是访问这个静态页面,那么这种每次加载都是加载这个html,效率也得到了提高!
5. 滚动加载，鼠标往下滚动才去会去发请求加载！

## 7.BitStatus(位状态)

![image-20211201192532483](https://gitee.com/miawei/pic-go-img/raw/master/imgs/image-20211201192532483.png)

位状态呢指在一个表中有多种状态,而且随着项目的发展这些状态要随之增加,那么按照我们传统的方式就用字段来表达,比如邮箱绑定就需要一个字段,而手机绑定也需要一个字段表示,而且这些往往只是用于表示是还是否的状态,那么我们可以采用一个位状态的方式!



如Long的二进制表示为8个0,那么每个状态占一个坑位,比如邮箱绑定就是第一个坑位,然后手机绑定占第二个坑位,那么如果用户绑定了手机认证那么就执行位操作,就好比是加法,然后计算得出新的二进制然后放进数据库,如果用户取消手机绑定那么就直接减去该状态所对应的二进制,通常这种状态都有一个约定成俗的规定,如:邮箱绑定就对应这5,那么在执行位操作的时候就会将5换算成二进制然后进行相关的运算!

工具类:

```java
/**
 * 用户状态类，记录用户在平台使用系统中所有的状态。
 * @author nixianhua
 */
public class BitStatesUtils {
	
	/**
	 * 用户注册成功的标示,及为默认初始状态
	 */
	public final static long OP_REGISTED = 1L << 0;
	/**
	 * 是否已激活（认证手机或认证邮箱）。
	 */
	public final static long OP_ACTIVED = 1L << 1;
	/**
	 * 是否锁定（未锁定则没有该状态），安全监测程序/后台对用户的锁定操作。
	 */
	public final static long OP_LOCKED = 1L << 2;
	/**
	 * 是否手机认证
	 */
	public final static long OP_AUTHED_PHONE = 1L << 3;
	/**
	 * 是否邮箱认证
	 */
	public final static long OP_AUTHED_EMAIL = 1L << 4;
	
	/**
	 * 是否完善个人信息
	 */
	public final static long OP_SAVE_BASIC_INFO = 1L << 5;
	
	/**
	 * 是否正在进行实名认证
	 */
	public final static long OP_IDENTITY_AUTHING = 1L << 6;
	
	/**
	 * 是否完成实名认证
	 */
	public final static long OP_IDENTITY_AUTHED = 1L << 7;
	/**
	 * 是否初始化支付密码
	 */
	public final static long OP_INIT_PAY_PASSWORD = 1L << 8;
	
	/**
	 * @param states 用户当前状态值
	 * @param value  需要判断状态值
	 * @return 是否存在
	 */
	public static boolean hasState(long states,long value){
		return (states & value) == value;
	}
	
	/**
	 * @param states 已有状态值
	 * @param value  需要添加状态值
	 * @return 新的状态值
	 */
	public static long addState(long states,long value){
		if(hasState(states, value)){
			return states;
		}
		return (states | value);
	}
	
	/**
	 * @param states 已有状态值
	 * @param value  需要删除状态值
	 * @return 新的状态值
	 */
	public static long removeState(long states,long value){
		if(!hasState(states, value)){
			return states;
		}
		return states ^ value;
	}
	
}
```



## 8.记录一些需求

1. 图片验证码

   ![image-20211204181657252](https://gitee.com/miawei/pic-go-img/raw/master/imgs/image-20211204181657252.png)

2. 短信验证码

   ![image-20211204181946721](https://gitee.com/miawei/pic-go-img/raw/master/imgs/image-20211204181946721.png)

## 9.Oauth2授权模式

这是介绍文章:http://www.ruanyifeng.com/blog/2014/05/oauth_2_0.html 

登录所用的协议就是Oauth2-----安全不会涉及第三方用户账号密码

OAuth 2.0定义了四种授权方式:

1. 授权码模式

   ![image-20211207160245436](https://gitee.com/miawei/pic-go-img/raw/master/imgs/image-20211207160245436.png)

​		授权流程:		

```
1. 用户访问客户端，后者将前者导向认证服务器
2. 用户选择是否给予客户端授权
3. 假设用户给予授权，认证服务器将用户导向客户端事先指定的"重定向URI"（redirection URI），同时附上一个授权码
4. 客户端收到授权码，附上早先的"重定向URI"，向认证服务器申请令牌。这一步是在客户端的后台的服务器上完成的，对用户不可见
5. 认证服务器核对了授权码和重定向URI，确认无误后，向客户端发送访问令牌（access token）和更新令牌（refresh token）
```

2. 简化模式

理解:简化模式（implicit grant type）不通过第三方应用程序的服务器，直接在浏览器中向认证服务器申请令牌，跳过了"授权码"这个步骤，因此得名。所有步骤在浏览器中完成，令牌对访问者是可见的，且客户端不需要认证

> 省略了授权码步骤, 在客户端同意授权以后直接往第三方服务获取token

3. 密码模式

理解:密码模式（Resource Owner Password Credentials Grant）中，`用户向客户端提供自己的用户名和密码。客户端使用这些信息，向"服务商提供商"索要授权`。

在这种模式中，用户必须把自己的密码给客户端，但是客户端不得储存密码。这通常用在用户对客户端高度信任的情况下，比如客户端是操作系统的一部分，或者由一个著名公司出品。而认证服务器只有在其他授权模式无法执行的情况下，才能考虑使用这种模式

> 用户向客户端发起登录请求, 然后第三方就会返回给客户端提供自己的账号和密码, 通过账号和密码来登录授权, 不过这个账号和密码是第三方的账号,不会去涉及客户端去保留之类的, 也就是说这个账号密码不会去在客户端做一个保存!---类似于我们在游戏授权的时候都是需要我们进行登录QQ来进行授权

4. 客户端模式

理解:客户端模式（Client Credentials Grant）指`客户端以自己的名义，而不是以用户的名义`，向"服务提供商"进行认证。严格地说，客户端模式并不属于OAuth框架所要解决的问题。在这种模式中，用户直接向客户端注册，客户端以自己的名义要求"服务提供商"提供服务，其实不存在授权问题。

> 以客户端自己的名义去往第三方获取资源, 不适合做登录, 只适合做一些自家平台的获取资源登录等等!
>
> 应用往第三方平台直接获取token,不会经过用户确认! 这种呢就不会存在授权啊这些问题!

### 9.1.JWT

jwt是一种令牌!它的出现就是为了解决在之前的使用的过程中我们每次访问资源都要通过资源服务器远程调用认证服务器进行token的校验和授权才能访问到资源。但是如果我们的`访问比较频繁`，并发比较高，那么这种权限校验方式无疑比较消耗性能。而JWT就是用来`解决远程校验令牌的问题`!



JWT:是一种轻巧的规范!这个规范允许我们使用JWT在`用户和服务器`之间传递安全可靠的信息

**理解**:使用JWT生产的Token是安全的，可以理解成就是在我们之前的Token基础上做了加密处理,实现了数据的安全传输，也实现了资源服务器对Token的自校验

特点:

1. 基于JSON，方便解析

2. 可以在令牌中定义内容，方便扩展

3. 非对称加密算法即数字签名，JWT防篡改

4. 资源服务使用JWT可以不依赖认证服务即可完成授权

---

组成部分:https://www.jianshu.com/p/99a458c62aa4

包含三部分组成:

1. 头部(header):

   ```json
   JSON格式，描述JWT的最基本的信息，如签名算法等效果如下：
   {"type":"JWT","alg":"HS256"} 这里指明了签名算法是HS256算法。在使用过程中会对该JSON进行BASE64编码如：yJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9
   ```

2. 载荷(playload):

   ```
   JSON格式，包含了需要的数据内容，也需要BASE64编码。包含三部分
   1. 标准中注册的声明（建议但不强制使用）
       iss: jwt签发者
       sub: jwt所面向的用户, zs
       aud: 接收jwt的一方
       exp: jwt的过期时间，这个过期时间必须要大于签发时间
       nbf: 定义在什么时间之前，该jwt都是不可用的.
       iat: jwt的签发时间
       jti: jwt的唯一身份标识，主要用来作为一次性token
   2. 公共的声明:
   	公共的声明可以添加任何的信息，一般添加用户的相关信息或其他业务需要的必要信息.但不建议添加敏感信息，因为该部分在客户端可解密
   3. 私有的声明:
   	私有声明是提供者和消费者所共同定义的声明，一般不建议存放敏感信息，因为base64是对称解密的，意味着该部分信息可以归类为明文信息
   	
   定义一个payload: 如 {"sub":"1234","name":"xxx","admin":true} 进行Base64编码后得到JWT第二部分如 eyJzdWIiOiIxMjM0NTY3ODkbmFtZSI6IkpvaG4gRG9lIiwiYW...
   ```

3. 签名(signature):

   ```
   通过指定的算法生成哈希，以确保数据不会被篡改。jwt的第三部分是一个签证信息，通过指定的算法生成哈希，以确保数据不会被篡改，这个签证信息由三部分组成：head(base64编码后的)；playload(base64编码后的)；secret(秘钥)
   签名后的密文构成JWT第三部分如：ThecMfgYjtoys3JX7dpx3hu6pUm0piZ0tXXr
   ```

> 最后JWT构建的内容编码后的字符串:“eyJhbGciOiJIUzI1NiJ9.eyJqdGkiOiI4ODgiLCJzdWIiOiLlsI_nmb0iLCJpYXQiOjE1NTc5MDQxODF9.ThecMfgYjtoys3JX7dpx3hu6pUm0piZ0tXXreFU_u3Y”



理解:其实这三部分分别是:

1. 头部: 存放JWT基本信息-->以JSON结构存储然后以Base64转码
2. 载荷: 存放主要的数据内容-->以JSON结构存储然后以Base64转码
3. 签名: 通过前两个部分再加一个秘钥通过算法生成一个签证信息-->Base64

然后最终的JWT就是将上面每部分的Base64再一次Base64编码就是最终的字符!

### 9.2.SpringCloud Oauth2

​	SpingSecurityOauth2实现了Oatuh2，SpingSecurityOauth2分为两个大块，一者为`认证授权`(Authorization Server)服务和`资源服务`(Resource server);

**认证授权服务**一般负责执行`认证逻辑`(登录)和`加载用户的权限`(给用户授权)，以及认证成功后的`令牌颁发` ，

**资源服务器**一般指的是我们系统中的微服务(被访问的微服务)，在资源服务器需要对用户的令牌(`认证成功与否`)，以及`授权(是不是有访问权限)做检查`

授权服务和资源服务的流程图：

![image-20211207163658139](https://gitee.com/miawei/pic-go-img/raw/master/imgs/image-20211207163658139.png)

以上是一种SpringCloud Oauth2的认证和授权的流程图!

![image-20211207163742678](https://gitee.com/miawei/pic-go-img/raw/master/imgs/image-20211207163742678.png)

这个就是一种标准的`授权码模式`!先获取授权码再通过授权码获取token, 根据token去请求资源信息!

----

1. 授权服务配置类:

   ```java
   package cn.miao.config;
   
   import org.springframework.beans.factory.annotation.Autowired;
   import org.springframework.context.annotation.Bean;
   import org.springframework.context.annotation.Configuration;
   import org.springframework.http.HttpMethod;
   import org.springframework.security.authentication.AuthenticationManager;
   import org.springframework.security.crypto.password.PasswordEncoder;
   import org.springframework.security.oauth2.config.annotation.configurers.ClientDetailsServiceConfigurer;
   import org.springframework.security.oauth2.config.annotation.web.configuration.AuthorizationServerConfigurerAdapter;
   import org.springframework.security.oauth2.config.annotation.web.configuration.EnableAuthorizationServer;
   import org.springframework.security.oauth2.config.annotation.web.configurers.AuthorizationServerEndpointsConfigurer;
   import org.springframework.security.oauth2.config.annotation.web.configurers.AuthorizationServerSecurityConfigurer;
   import org.springframework.security.oauth2.provider.client.JdbcClientDetailsService;
   import org.springframework.security.oauth2.provider.code.JdbcAuthorizationCodeServices;
   import org.springframework.security.oauth2.provider.token.AuthorizationServerTokenServices;
   import org.springframework.security.oauth2.provider.token.DefaultTokenServices;
   import org.springframework.security.oauth2.provider.token.TokenEnhancerChain;
   import org.springframework.security.oauth2.provider.token.TokenStore;
   import org.springframework.security.oauth2.provider.token.store.InMemoryTokenStore;
   import org.springframework.security.oauth2.provider.token.store.JwtAccessTokenConverter;
   import org.springframework.security.oauth2.provider.token.store.JwtTokenStore;
   
   import javax.sql.DataSource;
   import java.util.Arrays;
   
   //授权服务配置
   @Configuration
   //开启授权服务配置
   @EnableAuthorizationServer
   public class AuthorizationServerConfig extends AuthorizationServerConfigurerAdapter {
   
       //1.客户端详情配置(请求参数)
       @Autowired
       private DataSource dataSource ;
   
       @Autowired
       private PasswordEncoder passwordEncoder ;
   
       //1.1.注册客户端详情Bean,基于数据库,自动操作表：oauth_client_details
       @Bean
       public JdbcClientDetailsService jdbcClientDetailsService(){
           JdbcClientDetailsService jdbcClientDetailsService = new JdbcClientDetailsService(dataSource);
           //数据库的秘钥使用了PasswordEncoder加密
           jdbcClientDetailsService.setPasswordEncoder(passwordEncoder);
           return jdbcClientDetailsService;
       }
   
       /**
        * 客户端详情：配置客户端请求的参数
        *
        * @param clients 客户
        * @throws Exception 异常
        */
       @Override
       public void configure(ClientDetailsServiceConfigurer clients) throws Exception {
           clients.withClientDetails(jdbcClientDetailsService());
       }
   
       //2.授权服务端点配置(授权码，令牌)
   
       @Autowired
       private AuthenticationManager authenticationManager ;
   
       //2.1.定义授权码服务,连接数据库 oauth_code
       @Bean
       public JdbcAuthorizationCodeServices jdbcAuthorizationCodeServices(){
           return new JdbcAuthorizationCodeServices(dataSource);
       }
       //2.2.令牌服务配置
       //令牌的管理服务
       @Bean
       public AuthorizationServerTokenServices tokenService(){
           //创建默认的令牌服务
           DefaultTokenServices services = new DefaultTokenServices();
           //指定客户端详情配置
           services.setClientDetailsService(jdbcClientDetailsService());
           //支持产生刷新token
           services.setSupportRefreshToken(true);
           //token存储方式
           services.setTokenStore(tokenStore());
   
           //设置token增强 - 设置token转换器
           TokenEnhancerChain tokenEnhancerChain = new TokenEnhancerChain();
           tokenEnhancerChain.setTokenEnhancers(Arrays.asList(jwtAccessTokenConverter()));
           services.setTokenEnhancer(tokenEnhancerChain);  //jwtAccessTokenConverter()
   
           return services;
       }
   
       //2.3.配置Token的存储方案
       //基于内存的Token存储
       @Bean
       public TokenStore tokenStore(){
   //        return new InMemoryTokenStore();
           return new JwtTokenStore(jwtAccessTokenConverter());
       }
   
       //2.4.配置令牌转换器 ，设置JWT签名密钥。它可以是简单的MAC密钥，也可以是RSA密钥
       private final String sign_key  = "123";
   
       //JWT令牌校验工具
       @Bean
       public JwtAccessTokenConverter jwtAccessTokenConverter(){
           JwtAccessTokenConverter jwtAccessTokenConverter = new JwtAccessTokenConverter();
           //设置JWT签名密钥。它可以是简单的MAC密钥，也可以是RSA密钥
           jwtAccessTokenConverter.setSigningKey(sign_key);
           return jwtAccessTokenConverter;
       }
   
       /**
        * 授权服务断点：配置授权码和令牌的管理/存储方式
        *
        * @param endpoints 端点
        * @throws Exception 异常
        */
       @Override
       public void configure(AuthorizationServerEndpointsConfigurer endpoints) throws Exception {
           endpoints
               //1.密码授权模式需要 密码模式，需要认证管理器
               .authenticationManager(authenticationManager)
               //2.授权码模式服务
               .authorizationCodeServices(jdbcAuthorizationCodeServices())
               //3.配置令牌管理服务
               .tokenServices(tokenService())
               //允许post方式请求
               .allowedTokenEndpointRequestMethods(HttpMethod.POST);
       }
   
   
       /**
        * 授权服务安全配置：配置哪些路径放行(检查token的路径要放行)
        *
        * @param security 安全
        * @throws Exception 异常
        */
       @Override
       public void configure(AuthorizationServerSecurityConfigurer security) throws Exception {
           security
                   //对应/oauth/check_token ，路径公开
                   .checkTokenAccess("permitAll()")
                   //允许客户端进行表单身份验证,使用表单认证申请令牌
                   .allowFormAuthenticationForClients();
       }
   
   }
   ```

分析:

SpringSecurityOauth2提供了AuthorizationServerConfigurerAdapter适配器类来作为认证授权服务的配置,其中有三个方法源码如下：

```java
public class AuthorizationServerConfigurerAdapter  {
    //客户端详情：配置客户端请求的参数
    public void configure(ClientDetailsServiceConfigurer clients)...	
    //授权服务断点：配置授权码和令牌的管理/存储方式
    public void configure(AuthorizationServerEndpointsConfigurer endpoints)...
    //授权服务安全配置：配置哪些路径放行(检查token的路径要放行)
    public void configure(AuthorizationServerSecurityConfigurer security) ...
}
```

作用分别如下：

1. `ClientDetailsServiceConfigurer`：用来配置客户端详情服务：如配置客户端id(client_id)资源id、客户端密钥(secrect)、授权方式、scope等,可以基于内存或jdbc。(可以理解为是对浏览器向授权服务器获取授权码或令牌时需要提交的参数配置)
2. `AuthorizationServerEndpointsConfigurer`:配置令牌的访问端点url和令牌服务，如配置如何管理授权码(内存或jdbc)，如何管理令牌(存储方式，有效时间等等)
3. `AuthorizationServerSecurityConfigurer`: 用来配置令牌端点的安全约束，如配置对获取授权码，检查token等某些路径进行放行

授权服务配置分析:

![image-20211207165519707](https://gitee.com/miawei/pic-go-img/raw/master/imgs/image-20211207165519707.png)

总结:

授权服务配置了三个东西:

1. `ClientDetailsServiceConfigurer`:配置客户端信息，如同做微信登录的时候获取授权码和令牌时需要传入很多的参数，这些参数就是客户端详情配置的参数

2. `AuthorizationServerEndpointsConfigurer`:配置token相关端点，以及token如何存取，以及客户端支持哪些类型token

3. `AuthorizationServerSecurityConfigurer`:配置了端点就要对端点配置约束

----

**授权码模式获取token:**

先进行登录

![image-20211207165841539](https://gitee.com/miawei/pic-go-img/raw/master/imgs/image-20211207165841539.png)

第一步，通过浏览器获取授权码，GET访问:

http://localhost:1100/oauth/authorize?client_id=webapp2&response_type=code&redirect_uri=http://www.baidu.com ，操作如下：

![image-20211207165903812](https://gitee.com/miawei/pic-go-img/raw/master/imgs/image-20211207165903812.png)

![image-20211207165910412](https://gitee.com/miawei/pic-go-img/raw/master/imgs/image-20211207165910412.png)

第二步使用Postmain获取令牌，Post访问：

Url: [http://localhost:1100/oauth/token](http://localhost:3000/oauth/token)?client_id=webapp2&client_secret=123&grant_type=authorization_code&code=gD8ZbB&redirect_uri=http://www.baidu.com ，

操作如下：

![image-20211207165932700](https://gitee.com/miawei/pic-go-img/raw/master/imgs/image-20211207165932700.png)

---

密码授权模式:

在授权服务中我们配置了"password"密码模式,"authorization_code"授权码模式两种方式，接下来是测试“password”模式获取，将grant_type修改为“password” 添加username和password两个参数，去掉code参数:

![image-20211207165958237](https://gitee.com/miawei/pic-go-img/raw/master/imgs/image-20211207165958237.png)

----

刷新token:

http://localhost:3000/oauth/token?grant_type=refresh_token&refresh_token=刷新Token值&client_id=webapp&client_secret=secret

校验token:

http://localhost:3000/oauth/check_token?token=token值

访问资源 ，请求头带参数： “Authorization= Bearer token的值“-->注意Bearer后面有个空格!

----

当获取到token以后携带token去访问资源服务,那么在资源服务中也需要这样去配置:

```java
package cn.miao.config;

import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.security.config.annotation.method.configuration.EnableGlobalMethodSecurity;
import org.springframework.security.config.annotation.web.builders.HttpSecurity;
import org.springframework.security.oauth2.config.annotation.web.configuration.EnableResourceServer;
import org.springframework.security.oauth2.config.annotation.web.configuration.ResourceServerConfigurer;
import org.springframework.security.oauth2.config.annotation.web.configurers.ResourceServerSecurityConfigurer;
import org.springframework.security.oauth2.provider.token.TokenStore;
import org.springframework.security.oauth2.provider.token.store.JwtAccessTokenConverter;
import org.springframework.security.oauth2.provider.token.store.JwtTokenStore;

//ResourceServerConfigurer:资源服务器配置
//@EnableResourceServer:开启资源服务配置
@Configuration
@EnableResourceServer
@EnableGlobalMethodSecurity(prePostEnabled = true)
public class ResourceServerConfig implements ResourceServerConfigurer {

    //2.3.配置Token的存储方案
    //基于内存的Token存储
    @Bean
    public TokenStore tokenStore(){
        //return new InMemoryTokenStore();
        return new JwtTokenStore(jwtAccessTokenConverter());
    }

    //2.4.配置令牌转换器 ，设置JWT签名密钥。它可以是简单的MAC密钥，也可以是RSA密钥
    private final String sign_key  = "123";

    //JWT令牌校验工具
    @Bean
    public JwtAccessTokenConverter jwtAccessTokenConverter(){
        JwtAccessTokenConverter jwtAccessTokenConverter = new JwtAccessTokenConverter();
        //设置JWT签名密钥。它可以是简单的MAC密钥，也可以是RSA密钥
        jwtAccessTokenConverter.setSigningKey(sign_key);
        return jwtAccessTokenConverter;
    }

    //授权服务安全配置
    @Override
    public void configure(ResourceServerSecurityConfigurer configurer) throws Exception {
        //微服务的资源ID
        configurer.resourceId("courseId");
        //token的存储
        configurer.tokenStore(tokenStore());
    }

    //资源的授权规则配置
    @Override
    public void configure(HttpSecurity httpSecurity) throws Exception {
        httpSecurity.authorizeRequests()
                .antMatchers("/courseType/crumbs/**",
                        "/courseType/treeData",
                        "/swagger-ui.html","/**").permitAll()
                //校验scope必须为hrm ， 对应认证服务的客户端详情配置的clientId
                .antMatchers("/**").access("#oauth2.hasScope('hrm')")
                .anyRequest().authenticated()
                .and().csrf().disable();

    }
}
```

测试:

向资源服务器发起请求，请求头携带：`Authorization=Bearer token`值 ，如下:

![image-20211207173649167](https://gitee.com/miawei/pic-go-img/raw/master/imgs/image-20211207173649167.png)

​	这里我们已经成功的访问到真正的资源，请求资源之前，资源服务器会发送远程请求到授权服务器验证token的合法性，并且根据当前token获取权限列表，然后在进行授权，如果权限列表拥有资源(controller的方法)所需要的权限，即可访问成功;

错误示范：

如果Token是无效的会出现如下信息：

![image-20211207173733432](https://gitee.com/miawei/pic-go-img/raw/master/imgs/image-20211207173733432.png)

如果Token中的权限不包含资源所需要的权限会出现如下信息：

![image-20211207173754158](https://gitee.com/miawei/pic-go-img/raw/master/imgs/image-20211207173754158.png)

### 9.3. 微服务与微服务之间的授权

为什么?

​	当客户端先资源服务发起请求，请求头携带Token，在资源服务(A)需要校验Token进行访问授权，但是我们一个请求往往是需要多个微服务一起完成，如果A服务调用B服务调用C服务，那么A服务校验Token之后，B服务需不需要也校验Token呢？答案是当然的，因为每个微服务都是独立的都需要做好权限校验工作？那么如何实现服务之间的授权？



解决方案:

​	直接把客户端提交给资源服务的Token继续向下游资源服务提交，那么就需要在消费者服务A向提供者服务器B发起请求(Feign)的时候进行拦截(Feign的拦截器)，在拦截器中获取请求头中的Token添加到Fiegn的请求头中，这样一来Token就由A服务传递给了B服务，B服务就可以对Token进行校验了。如图

![image-20211207174224358](https://gitee.com/miawei/pic-go-img/raw/master/imgs/image-20211207174224358.png)

这样虽然在发起请求的时候拦截并手动的添加到目标服务的请求头中,可是如果遇到hystrix那么这也就会暴露出一个问题: `资源隔离`!

![image-20211207174454312](https://gitee.com/miawei/pic-go-img/raw/master/imgs/image-20211207174454312.png)

解决方案:

![image-20211207174518001](https://gitee.com/miawei/pic-go-img/raw/master/imgs/image-20211207174518001.png)

解决:

理解:

​	其实看到这张图也就懂了,在A服务向B服务发起调用的时候那么就需要将Token权限给带过去,那么这个过程是这样的: 首先一个请求会在A线程里执行,那么进入到Hystrix的线程池中因为hystrix的资源隔离的特性会让A请求不在A线程里执行而是更换新的线程B里面执行,那么这开始执行的线程和最后执行的线程是不一致的!所以我们需要修改线程池并发策略,在更换新的线程的时候手动的将开始的请求中的token手动添加到目标线程里面,然后还需要在B服务接收的时候需要使用Feigin拦截器去获取令牌然后放进请求头中!这样token才会进行目标的资源进行判断是否授权!



请求拦截:

```java
//Fiegn拦截器----调用的那一方获取到的拦截器,如B服务
@Component
public class DefaultOAuth2FeignRequestInterceptor implements RequestInterceptor {

    //请求头中的token
    private final String AUTHORIZATION_HEADER = "Authorization";
    
    @Override
    public void apply(RequestTemplate requestTemplate) {

        //1.获取请求对象
        ServletRequestAttributes servletRequestAttributes = (ServletRequestAttributes) RequestContextHolder.getRequestAttributes();
        HttpServletRequest request = servletRequestAttributes.getRequest();

        //2.从请求头获取到令牌
        String authorization = request.getHeader(AUTHORIZATION_HEADER);

        //3.把令牌添加到Fiegn的请求头
        requestTemplate.header(AUTHORIZATION_HEADER,authorization);
    }

}
```

修改线程池并发策略:

```java
@Configuration
@Slf4j
public class FeignHystrixConcurrencyStrategy extends HystrixConcurrencyStrategy {

    private HystrixConcurrencyStrategy hystrixConcurrencyStrategy;

    public FeignHystrixConcurrencyStrategy() {
        try {
            this.hystrixConcurrencyStrategy = HystrixPlugins.getInstance().getConcurrencyStrategy();
            if (this.hystrixConcurrencyStrategy instanceof FeignHystrixConcurrencyStrategy) {
                return;
            }
            HystrixCommandExecutionHook commandExecutionHook =
                    HystrixPlugins.getInstance().getCommandExecutionHook();
            HystrixEventNotifier eventNotifier = HystrixPlugins.getInstance().getEventNotifier();
            HystrixMetricsPublisher metricsPublisher = HystrixPlugins.getInstance().getMetricsPublisher();
            HystrixPropertiesStrategy propertiesStrategy =
                    HystrixPlugins.getInstance().getPropertiesStrategy();

            HystrixPlugins.reset();
            HystrixPlugins instance = HystrixPlugins.getInstance();
            instance.registerConcurrencyStrategy(this);
            instance.registerCommandExecutionHook(commandExecutionHook);
            instance.registerEventNotifier(eventNotifier);
            instance.registerMetricsPublisher(metricsPublisher);
            instance.registerPropertiesStrategy(propertiesStrategy);
        } catch (Exception e) {
            System.out.println("策略注册失败");
        }
    }

    @Override
    public <T> Callable<T> wrapCallable(Callable<T> callable) {
        //此时在 A 线程 ,拿到请求
        RequestAttributes requestAttributes = RequestContextHolder.getRequestAttributes();
        //新开线程，把请求传入进去
        log.info("线程{} ， 拿到请求 {}", Thread.currentThread().getName(),requestAttributes);
        return new WrappedCallable<>(callable, requestAttributes);
    }

    @Override
    public ThreadPoolExecutor getThreadPool(HystrixThreadPoolKey threadPoolKey,
                                            HystrixProperty<Integer> corePoolSize,
                                            HystrixProperty<Integer> maximumPoolSize,
                                            HystrixProperty<Integer> keepAliveTime,
                                            TimeUnit unit, BlockingQueue<Runnable> workQueue) {
        return this.hystrixConcurrencyStrategy.getThreadPool(threadPoolKey, corePoolSize, maximumPoolSize, keepAliveTime,
                unit, workQueue);
    }

    @Override
    public ThreadPoolExecutor getThreadPool(HystrixThreadPoolKey threadPoolKey,
                                            HystrixThreadPoolProperties threadPoolProperties) {
        return this.hystrixConcurrencyStrategy.getThreadPool(threadPoolKey, threadPoolProperties);
    }

    @Override
    public BlockingQueue<Runnable> getBlockingQueue(int maxQueueSize) {
        return this.hystrixConcurrencyStrategy.getBlockingQueue(maxQueueSize);
    }

    @Override
    public <T> HystrixRequestVariable<T> getRequestVariable(HystrixRequestVariableLifecycle<T> rv) {
        return this.hystrixConcurrencyStrategy.getRequestVariable(rv);
    }

    static class WrappedCallable<T> implements Callable<T> {
        private final Callable<T> target;

        //A线程扔过来的请求
        private final RequestAttributes requestAttributes;

        public WrappedCallable(Callable<T> target, RequestAttributes requestAttributes) {
            this.target = target;
            this.requestAttributes = requestAttributes;
        }

        @Override
        public T call() throws Exception {
            try {
                //此时的代码在 B 线程 ，把请求设置到 RequestContextHolder
                RequestContextHolder.setRequestAttributes(requestAttributes);
                log.info("线程执行{} ， 设置请求到RequestContextHolder {}", Thread.currentThread().getName(),requestAttributes);
                return target.call();
            } finally {
                RequestContextHolder.resetRequestAttributes();
            }
        }
    }
}
```

---

获取当前登录用户的信息

​	其实这种呢我们可以在用户登录认证的时候有一个`Userdetailservice`里查询用户信息进行修改, 一次性查询出想要的信息,然后通过JSON序列化返回给客户端, 然后下次我们想要的时候就会通过一个工具类去获取然后转换为实体类:

```java
@Component
@Slf4j
public class MyUserDetailService implements UserDetailsService {

    @Autowired
    private ILoginService loginService ;

    @Autowired
    private PermissionMapper permissionMapper ;

    @Override
    public UserDetails loadUserByUsername(String username) throws UsernameNotFoundException {

        Login login = loginService.selectOne(new EntityWrapper<Login>().eq("username", username));
        Assert.notNull(login, "用户不存在!");

        //查询用户的权限
        List<GrantedAuthority> authorities = new ArrayList<>();
        List<Permission> permissions = permissionMapper.selectPermissionsByUserId(login.getId());
        if(CollUtil.isNotEmpty(permissions)){
            authorities = permissions.stream().map(p -> new SimpleGrantedAuthority(p.getSn()) ).collect(Collectors.toList());
        }

        log.info("加载用户的权限 {}",authorities);
        authorities.forEach(System.out::println);

        //获取用户上下文信息, 那么可以用户登录的时候通过查询的login就查询出所需要的字段信息,放入token中
        //下次获取的时候我们可以通过scurity中的ScurityContextHolder来获取用户的信息

        Map<Object, Object> build = MapUtil.builder().put("id", login.getId()).put("username", login.getUsername()).put("tenantId", login.getTenantId()).put("tenantName", login.getTenantName()).build();
        //用户名
        return new User(JSONObject.toJSONString(build),
                login.getPassword(),//密码
                true,true,true,true,
                authorities);//权限
    }
}
```

获取工具类:

```java
public class LoginContext {

    public static Login getLogin(){
        try {
            SecurityContext context = SecurityContextHolder.getContext();
            //这里就能获取到校验token中的user_name, 这里封装了我们想要的数据
            String principal = (String)context.getAuthentication().getPrincipal();
            return JSONObject.parseObject(principal, Login.class);
        } catch (Exception e) {
            e.printStackTrace();
            return null;
        }
    }
}
```

### 9.4 小结

理解JWT:

```
jwt是一种规范!这个规范允许我们在用户和服务之间传递可靠的信息 , 传输使用的JSON结构来传输,又是存在数字签名所以传输时可靠的!并且使用token进行加密然后解密!    
```

好处:其实使用jwt这种token方案比之前的redis缓存也有一定的好处,之前需要依赖于redis服务去存储权限和用户信息去放在redis中,每次需要用到都需要去拿然后解析,而现在只需要将信息放在客户端,由客户端去保存信息,然后每次获取的时候携带到对应服务中然后解析获取权限, 依赖度也降低了!

我们可以理解为就是在之前生成的token的基础之上进行了加密! 并且这种token方式无需放在redis缓存中而是存放在客户端, 客户端就存放的是用户的权限等信息, 所以资源服务就会根据这个token进行解密然后就会走security进行授权的流程!

![image-20211207191754350](https://gitee.com/miawei/pic-go-img/raw/master/imgs/image-20211207191754350.png)



对于Spring Security oauth2的权限和token,我总结分两大块:

1. **认证服务**:登录认证授权和颁发token;
2. **资源服务**:解析token获取权限判断是否有权限;

整个的执行的流程:

​	认证服务:

```
用户在浏览器通过表单登录,这时就会携带账号和密码提交到认证服务中,这时就会封装携带clientID和秘钥一起发送请求获取token,那么此时就会走scurity的认证流程,通过一层一层认证通过username查询用户,最后查询出用户信息和对应的权限信息一并返回,这时登录认证的工作就完成了,那么接下来就是走JWT的颁发token的一个过程: 根据clientID去客户端详情表中查询获取颁发token所需要的参数,然后根据scurity认证获取的权限信息利用JWT封装成一个密文, 这个密文就是转为Base64后的token,然后将其token返回给客户端!
```

​	资源服务:

```
在访问其他资源的时候就会携带上这个token去访问,那么在资源服务里就会根据在认证服务里根据密文生成的token,此时就会根据相同的秘文去解析整个token,解析后获取对应的权限列表和一些其他参数信息,然后就判断resourceID做一个资源的大的判断,然后接下来就会走scurity的授权流程根据方法上的注解的权限进行判断, 如果满足,哎就放行,如果不满足,哎就打回!
```

总结:

![image-20211207182235873](https://gitee.com/miawei/pic-go-img/raw/master/imgs/image-20211207182235873.png)

其实就往大的一个方向去说: 先认证后颁发token, 然后解析token然后走授权流程!------这就是JWT微服务token方案!

----

服务之间授权的理解:	

```
按照正常的调用过程中,我们会携带一个token去调用另一个服务,但是在调用过程中我们是使用的是HTTP调用,那么token是没有带过去的,那么就需要我们使用feigin拦截手动将请求头的token添加目标请求的请求头中!但是要知道feigin是集成了hystrix,那么我们知道hystrix里面有一个资源隔离的说法,一个信号量一个线程池; 就会造成A请求是在A线程里面,当经过hystrix的线程池中,就会将A线程更换为B线程去执行,那么此时请求头中的token也会丢失,所以解决办法:
1. 信号量(自始至终都是一个线程)
2. 修改线程池并发策略

我们要做的就是第二个解决办法,就是在覆写线程池并发策略手动将A线程中的token放入到B线程中去! 然后在目标服务中使用feigin拦截器拦截并将B线程中的token放入到请求头中去!
```

为什么换个线程请求就不在了?

​	因为首先A请求中的token是单个线程独有的,当执行到线程池这里就会新开一个线程,比如线程B, 那么之前的请求中的token在A线程有那么到线程B就不存在了!



## 10.单点登录和无感刷新

在微服务中发起请求将token通过zuul就会拦截token ,解决办法:

zuul会默认认为浏览器请求头中会存在敏感信息,所以就会屏蔽拿不到token,所以解决办法就是在yaml中配置修改默认存在敏感信息即可!

```yaml
zuul:
  sensitive-headers:     #把zuul忽略敏感请求头的配置覆盖为空
```

请求状态:

401: 过期或者token不存在

403: 没有权限

----

单点登录:

概念:是指在一个网站登录那么其他的网站的就不需要登录了,就好比京东的网站,你在一个站点登录了那么在其他站点就不需要登录了!

不同的站点服务器只要任一地方登录那么访问任何地方都是已经登录的状态!



那么这个如何实现的呢?

将之前存在localStorage中的token改存于cookie中, 然后将cookie中的domain修改为几个服务器域名共同访问,如: [www.hrm.com](http://www.hrm.com)  admin.hrm.com  那么就可以修改为 .hrm.com 那么只要包含这个域名下这个cookie都可以访问!

如何修改本地hosts文件:

```java
127.0.0.1 admin.hrm.com
127.0.0.1 user.hrm.com
```

以上就是模拟几个站点的域名

然后在一个前端站点登录的时候:

![image-20211207193055416](https://gitee.com/miawei/pic-go-img/raw/master/imgs/image-20211207193055416.png)

将其添加cookie,注意此时domain作用域是`.hrm.com`,也就是说只要域名是.hrm.com后缀的都可以享有这个cookie!那么也就是说只要一次登录那么此时cookie就有了,那么其他站点访问资源的时候就会从cookie里面拿就获取用户的登录信息了!

![image-20211207195236324](https://gitee.com/miawei/pic-go-img/raw/master/imgs/image-20211207195236324.png)

-----

无感刷新:

概念: 如用户在浏览网页的时候如果突然token过期了那么此时就会影响客户的一个浏览体验,所以我们可以采用无感刷新让用户没有感觉一样的浏览网页!

根据返回状态请重新刷新token,  然后获取token再覆盖本地的token,再 重新发起请求---无感token 对于用户来说是没有任何的感觉的!

token存在过期的几种情况?

1. 对于客户端:如果在cookie里那么也有过期时间就会自动消失
2. 对于服务端:本身来讲token里面就有一个过期时间,如果到了过期时间你再去访问那么就会报出过期的异常信息!



解决办法:

1. 延长token的过期时间
2. 使用刷新token去刷新获取token

因为第一次登录获取token的时候就有一个本身的token还有一个刷新token, 那么我们可以利用刷新token来获取新的token然后存于客户端!



实战:

前端:添加请求响应拦截器

这里判断了如果是401的响应代表Token过期，重新组装参数刷新Token,然后重新设置到localStorage,然后调用  ***\**axios\**\***.request 继续执行请求 ， 需要注意的是刷新Token的请求必须是同步的，因为我们需要拿到Token后才能继续发请求。

```javascript
//处理Token刷新========================================================================
axios.interceptors.response.use(config => {
    return config
},error => {
    if (error && error.response) {
        console.log(error);
        switch (error.response.status) {
            case 401: return doRequest(error);
            case 403: return doNoPerHandler(error);
        }
    }
    Promise.reject(error)
});
function doNoPerHandler(error) {
    alert("没访问权限");
}
async function doRequest (error) {
    try {
        //获取新的Token
        const data = await getNewToken();
        var token = data.data.resultObj.access_token;
        var refresh_token = data.data.resultObj.refresh_token;
        sessionStorage.setItem("U-TOKEN",token);
        sessionStorage.setItem("R-TOKEN",refresh_token);
        //继续执行上一次失败的请求
        const res = await axios.request(error.config);
        return res;
    } catch(err) {
        alert("登录失效,请重新登录");
        sessionStorage.clear();
        router.replace({ path:"/login" });
        return err;
    }
}

//刷新Token
async function getNewToken() {
    var refreshToken = sessionStorage.getItem('R-TOKEN');
    if(refreshToken){
        return await axios({
            url: '/auth/login/refresh?refreshToken='+refreshToken+"&type=1",
            method: 'post',
            headers: {
                'Content-Type':'application/x-www-form-urlencoded'
            }
        })
    }else{
        alert("登录失效,请重新登录");
        sessionStorage.clear();
        router.replace({ path:"/login" });
    }
}

//处理Token刷新end================================================================
```

后台刷新:

```java
//系统刷新
@RequestMapping(value="/refresh")
public AjaxResult refresh(@RequestParam("refreshToken") String refreshToken,@RequestParam("type") Integer type){
    AccessTokenVo accessTokenVo = loginService.refresh(refreshToken,type);
    return AjaxResult.me().setResultObj(accessTokenVo);
}

@Override
public AccessTokenVo refresh(String refreshToken,Integer type) {
    //根据传入的type,得到对应的客户端配置
    Oauth2ClientDetails clientDetails = properties.getClientDetials(type);

    //1.拼接一个获取oath2的token的url:密码模式
    String url = String.format(URL_TOKEN_REFRESH, clientDetails.getClientId(),
            clientDetails.getSecret(),refreshToken);
    //2.发送请求获取token
    Map<String, String> map = HttpUtil.sendPost(url);
    //3.封装结果
    String tokenJson = JSON.toJSONString(map);
    return JSON.parseObject(tokenJson,AccessTokenVo.class );
}
```

-----

面试题:

1. Token失效了怎么办?
   - 我们可以做无感刷新
2. 注销了怎么办?
   - 删除前端存储的token(包括刷新token)
3. Token丢失怎么办，别人拿到你的Token来访问你的系统？
   - 其实这个问题怎么可能嘛,反过来想这个token是保存在我们的浏览器中我的电脑中,如果别人能拿到难道这不就是在黑客入侵我的电脑,难道此时关注的重点是token被拿? 如果是身边的人拿那么我们也可以做一个自动锁屏的功能? 对于一般的用户来讲它都不会去点开F12更不会去操作token!并且会想token是不会暴露给用户的, 因为这是放在请求头中的!
4. 讲一下你们的认证授权的总体流程?
   - 首先用户在前端发起表单登录,然后此时就会请求到我们认证服务中,我们拿到账号和密码去通过SpringSecurity去进行认证的一个流程(通过loginDetailService查询),此时我们能拿到用户的权限等信息,然后根据后台自己定义的clientID去客户端参数详情表中查询生成token所需要的参数,然后根据秘钥将权限和参数生成一个密文,这个密文就是token,然后将这个token返回给客户端进存储
   - 访问资源服务的时候就会携带这个token,然后在资源服务中根据生成token相同的密文进行令牌转换器解析,通过解析后得到权限信息, 进行校验SourceID和scope,如果满足就执行下一步,然后访问到具体的方法上的security的权限注解,那么此时就会进入security的授权的流程,如果满足这个权限就会开放资源,如果不满足那么就会直接拒绝访问!

## 11. 事务

### 11. 1 事务基本概念

事务具有四个特性(简称ACID原则):

1. 原子性
   - 不可分割，指一个事务就是一个整体无法分割的独立单元，不允许部分成功部分失败！
   - 利用InnoDb的undo log,会记录这些回滚需要的信息，当事务执行失败或调用rollback，导致事务需要回滚，就可以利用undo log中的信息将数据回滚到修改之前的样子。
   
2. 一致性（基于其他三个）

   - 一致性要求写到数据库的数据都必须满足于预先定义的规则，可以理解为写之前和写入数据库的数据要达到一致！
   - 当然如果我们满足其他三个原则那么自然也就达到了一致性！

3. 持久性

   - redo log实现了事务的持久性
   - redo log记录的是新数据的备份，在事务提交之前，只要将Redo Log持久化即可，注意不需要将数据持久化，也就是说当系统发生崩溃的时候，虽然数据没有持久化但是redo log已经持久化了，系统就可以根据redo log中的内容，将所有数据恢复到最新的状态！

   ```java
   Undo+ Redo事务的简化过程
   A.事务开始. 
   B.记录A=1到undo log. 
   C.修改A=3. 
   D.记录A=3到redo log. 
   E.记录B=2到undo log. 
   F.修改B=4. 
   G.记录B=4到redo log. 
   H.将redo log写入磁盘。 
   I.事务提交
   ```

   通过undo保证事务的原子性，redo保证持久性。

   4. 隔离性

      - 隔离性要求如果两个事务修改同一个数据，则必须按顺序执行，并且前一个事务如果未完成，那么未完成的中间状态对另一个事务不可见

      ---

   四种隔离级别:

   1.  读未提交
   2. 读已提交
   3. 可重复读
   4. 串行化

   以上的隔离级别都要解决的问题:

   1. 脏读(一般读未提交会出现这类问题)

      ```
      脏读指的是读到了其他事务未提交的数据,未提交也就意味着这些数据都有可能出现回滚,那么也就是说读到了不存在的数据
      解决办法:
      set global transaction isolation level read committed
      但是无法解决重复读和解决不了幻读
      ```

   2. 不可重复读(一般读已提交会出现这类问题)

      ```
      同一个事务中多次使用相同条件读取到的数据是不一样的,也就是说其他事务有可能使用update修改了数据造成两次或多次读到的数据都是不一致的!
      解决办法:
      set global transaction isolation level repeatable read
      但是无法解决幻读问题
      ```

   3. 幻读(一般重复读就可能出现这类问题)

      ```
      事物A两次读取相同条件的数据读到的条数不一样
      解决办法:
      事务A两次读取读取到了不同的数据条数，这个就是幻读，但是当你在 MySQL 中测试幻读的时候，并不会出现这类问题，幻读并没有发生，因为MySQL 的可重复读隔离级别其实解决了幻读问题，它使用到了“间隙锁”。
      ```

   4. 丢失更新

      ```
      1. 回滚丢失: 如两个事务同时修改同一条数据,事务A完成了修改,事务B遇到突然情况进行回滚那么就会将事务A的修改数据进行回滚丢失
      2. 覆盖丢失: 如两个事务同时修改同一条数据,事务A完成了修改,事务B再次修改并提交那么就有可能出现事务B的结果就会去覆盖事务A的结果
      ```

串行化:

​	串行化是4种事务隔离级别中隔离效果最好的，解决了脏读、可重复读、幻读的问题，但是效果最差，它将事务的执行变为顺序执行，与其他三个隔离级别相比，它就相当于单线程，后一个事务的执行必须等待前一个事务结束

注意: MySQL事务隔离依靠的是锁来实现的! 

**MVCC机制**

MVCC的全称是"多版本并发控制"，一个行记录数据有多个版本对快照数据，这些快照数据在undo log中。 如果一个事务读取的行正在做DELELE或者UPDATE操作，读取操作不会等行上的锁释放，而是读取该行的快照版本；

**可重复读**是在事务开始的时候生成一个当前事务全局性的快照，而**读已提交**则是每次执行读语句的时候都重新生成一次快照

![image-20211210195915446](https://gitee.com/miawei/pic-go-img/raw/master/imgs/image-20211210195915446.png)







### 11.2 分布式解决方案

#### 1. 2PC

1. ### XA规范

   XA协议采用两阶段提交方式来管理分布式事务采用两阶段提交 2PC（Two Phase Commitment Protocol）来管理分布式事务，所谓二阶段是有两个阶段组成，一阶段投票阶段和二阶段提交阶段。同时它是由“事务协调器”和若干“事务执行者”两个角色组成

   第一阶段：投票阶段

   ![在这里插入图片描述](https://gitee.com/miawei/pic-go-img/raw/master/imgs/20200426141815981.png)

解读：首先事务协调器会往所有的事务参与者发起提交请求（询问是否准备OK），那么此时事务参与者就会执行事务操作，就会将旧数据写入到Undo log然后将新的数据写入redo log,然后此时先不会执行持久化到数据库磁盘，然后这些操作准备ok那么就会给事务协调器返回准备ok！

​	第二阶段：提交阶段

![在这里插入图片描述](https://gitee.com/miawei/pic-go-img/raw/master/imgs/20200426141950337.png)

正常流程：当所有的事务参与者都准备OK了，那么事务协调器就会执行提交事务的指令那么参与者接收到指令就会将redo log中的数据写入到磁盘数据库中！

回滚流程：

![在这里插入图片描述](https://gitee.com/miawei/pic-go-img/raw/master/imgs/20200426142424513.png)

当事务参与者操作失败就会给事务协调器恢复不OK，那么此时事务协调器就会给其他事务参与者发送rollback指令说大家都散了吧今天这事搞不成了。然后此时其他参与者接收到指令后就把undo log中的回滚信息进行回滚!

2. ### Seata

Seata 的设计思路是将一个分布式事务可以理解成一个全局事务，下面挂了若干个分支事务，而一个分支事务是一个满足 ACID 的本地事务，因此我们可以操作分布式事务像操作本地事务一样。

全局事务执行流程如下:

![Seata执行流程](https://gitee.com/miawei/pic-go-img/raw/master/imgs/20200428003910751.png)

理解: 

1. TC事务协调器是一个独立的服务我们需要先启动它,他是负责维护全局事务的运行状态,根据TM的指令来对全局事务的提交或回滚!
2. RM资源管理器这个呢就好比是我们需要事务的服务(理解为这个被调用的服务需要开启事务)
3. TM事务管理器只是负责开启一个全局事务,用于通知TC去提交或者回滚事务! (理解为这也是服务由它主动发起事务)

执行流程:

	1. 系统启动TM事务管理者以及RM资源管理者需要向事务协调器进行`提交注册`---可以看做这是一种初始化!
	1. 在事务管理器的主业务方法上打上@GlobalTransationl注解，通过这个注解,事务管理器会向TC申请`开启一个全局分布式事务`,然后TC返回一个全局唯一的XID，这个XID就会在涉及微服务的整个全局事务的上下文中进行传播！
	1. 业务开始, 事务管理器通过Feign去调用Order，并传递全局事务XID，然后Order在做修改操作的时候就会往事务协调器TC注册本地分支事务（通过代理DataSource向TC发起分支事务注册的），该分支事务归属于相同XID的全局事务，然后协调者TC返回一个分支事务ID;
	1. 这个时候Order就会正常写数据库，然后会写入一个undo log，然后提交分支事务，最后向TC上报事务处理状态。
	1. 当order调用完成以后，代码回到事务管理器然后就会往TC事务协调者发起全局事务提交请求，TC向RM事务分支发起事务提交请求，RM直接删除undo log日志文件即可，因为之前就已经提交了事务

理解：

TM: 发起事务的地方

RM:接收事务的地方

TC: 独立服务,可理解为协调全局事务的组件而已!

1. 首先TM和RM都启动第一件事就是先往TC进行注册。
2. 然后TM在主事务方法上需要打一个@GlobalTransational注解，这个注解就往TC申请开启全局分布式事务，开启成功就会返回一个全局唯一的XID。
3. 第三步就开始执行事务方法中的业务逻辑，然后就会通过Feign去调用RM，然后RM就会往TC注册本地分支事务，而这个分支事务也归属到相同XID的全局事务中（是通过代理DataSource进行发起分支事务注册），
4. 第四步RM就会正常执行将数据写入到数据库，不过先将数据先写入到undo log中用于回滚的时候好恢复，然后将数据写入到数据库后就提交分支事务然后向TC上报事务处理状态！
5. 第五步执行完毕之后就会一路回到TM事务发起方法这里，此时TM就会向TC发起全局事务提交请求，TC呢就往注册的分支事务发起提交请求，如果执行都ok那么RM就会删除undo log日志文件，因为这个时候就已经提交了本地事务！

失败的情况：

![在这里插入图片描述](https://gitee.com/miawei/pic-go-img/raw/master/imgs/20200428003944632.png)

理解： 在之前的步骤中在RM中会去写入到数据库中，如果此时出现异常情况那么就会将异常情况上报给TC，然后一路返回到TM，TM收到之后就会往TC发起一个全局性事务的回滚请求，而此时RM收到TC发起的回滚指令后就会去解析undo log把数据还原到之前，删除undo log提交本地事务！











#### 2. TCC

理解：按照事先预定的方案去执行，如果失败了就走补偿方案(撤销)

- Try : try的意思是尝试，其实这个步骤是用来做业务的预处理，可以理解为是做一些准备工作，等到Confirm之后这些操作才算成功。
- Confirm ：确认，如果所有的事务参与者都try成功，执行commit对业务做提交操作，或者可以理解成对try的工作作出确认。
- Cancel：取消，如果try失败需要回滚，即取消try的预处理操作

正常流程：

![在这里插入图片描述](https://gitee.com/miawei/pic-go-img/raw/master/imgs/20200428203908312.png)

回滚流程：

![在这里插入图片描述](https://gitee.com/miawei/pic-go-img/raw/master/imgs/20200428203855256.png)

#### 3. MQ消息最终一致性

![在这里插入图片描述](https://gitee.com/miawei/pic-go-img/raw/master/imgs/20200428213448353.png)

大致流程是：

1.主业务方向发送一个“Prepared”消息到MQ，这个消息还未被确认，然后主业务方执行自己的业务，并提交本地事务，成功后向MQ确认之前的“Prepared”消息。

2.消息接受者方收到消息后执行业务逻辑，提交本地事务，然后做一个消息签收，如果消费者消息接受失败会进行重试，保证消息最终被消费。



那么这种最终消息一致性指数据只是最终的一致性, 有可能是一个小时之后也有可能是一天之后,总之最终达到一致性的原则!

#### 4. 最大努力通知

最大努力通知服务表示在不影响主业务的情况下，尽可能地确保数据的一致性。它需要开发人员根据业务来指定通知规则，在满足通知规则的前提下，`尽可能`的确保数据的一致，以达到最大努力的目的。

场景: 支付宝结果通知



最大努力通知与可靠消息一致性有什么不同 ?

1. 可靠消息最终一致性

   ```
   系统A本地事务执行成功，通知系统B处理任务，通常通过MQ实现。一般适用于平台内部，对一	致性要求相对较高(微服务的2个子系统之间)
   ```

2. 最大努力通知

   ```
   所谓最大努力通知就是系统A用最大努力通知系统B，能不能成功，不做完全保证，如果没通知到位，	系统B可以主动来调用系统A的接口查询结果状态。一般适用于跨平台业务，或对接了上方平台的业务场景(支付结果通知)
   ```

#### 5. 总结

![image-20211210194540187](https://gitee.com/miawei/pic-go-img/raw/master/imgs/image-20211210194540187.png)

需要注意的地方是

1. 2PC是有两个方案一个是XA一个是Seata,
   - XA是基于数据库层面的, 在准备阶段就会写undo log 日志和redo log日志但是还未提交处于等待状态，然后需要事务协调器来发起提交指令才会将redo log 中的数据写入到磁盘中，这种会锁定资源时间较长，如果其中响应时间较长那么就会造成事务的阻塞，性能也不好！
   - Seata是基于应用层面的，它呢执行的时候只写入一个undo log回滚日志，而数据就写入到数据库，然后上报状态后续如果正常执行就删除undo log日志，如果非正常那么就会利用undo log 进行回滚恢复数据。这种方案呢在第一阶段就提交了事务，性能较好！
2. TCC：是一种补偿性的，弱一致性事务方案
   - 这种也有一个准备-提交-取消这三个阶段，只不过这个呢区别比较大， 这个对代码的侵入性比较强会去调用各种各样的接口
3. 最终一致性：不要求数据的强一致性但是最终你得给我一致！
   - 消息重复消费和可靠消费：将消息保存在数据库表中，然后记录状态然后通过定时器去定时检索去发送消息到MQ中，MQ接收那一方就会执行业务保证最终一致性，当然存在失败的情况，那么定时器也会去检索再一次发送等等！
4. 最大努力通知：顾名思义尽可能尽努力，不保证一致性！



### 11.3 分布式锁

#### 1. 概念

为什么需要分布式锁：

1. 单体项目：在单进程（启动一个jvm）的系统中，当存在多个线程可以同时改变某个变量（可变共享变量）时，就需要对变量或代码块做同步!---在java中可以通过synchronize和lock等手段来实现
2. 分布式项目:
   - 问题: 
     - 分布式与单机情况下最大的不同在于其不是多线程而是`多进程`
     - 多线程由于可以共享堆内存，因此可以简单的采取内存作为标记存储位置。而进程之间甚至可能都不在同一台物理机上，因此需要将标记存储在一个所有进程都能看到的地方
   - 解决办法:
     - 分布式锁作用就是在分布式系统，保证某个方法只能在同一时间某个进程的某个线程执行。在整个分布式环境下都只有一份! --------- `锁是多个进程共享的`

总结: 就是在在分布式环境下，保证某个公共资源只能在同一时间被多进程应用的某个进程的某一个线程访问时使用锁



重复锁: 允许同一个线程多次获取同一把锁: 如递归函数内有加锁操作

自旋锁: 一个线程获取一把锁的时候,这个锁已经被占用了那么此时就会进入阻塞等待状态，并等待一段时间后再次尝试获取的状态！ 



分布式锁的三种方式：

1. 基于数据库操作
2. 基于redis缓存操作
3. 基于zookeeper临时顺序节点+watch

#### 2.数据库

1. 行锁(默认操作)

   - 共享锁: 在进行读操作的时候，共享锁与共享锁之间会进行兼容，允许多个事务同时获取该锁

   - 排它锁：在进行写操作的时候，排它所是具有互斥的作用，也就是当一个事务获取锁的时候是不行允许其他事务获取锁，也即是说不存在不兼容的情况！

   - 如果我们想要再查询的时候修改的排他锁那么我们可以这样做:

     ```mysql
     select * from table where xx = yy for update   
     ```

   **悲观锁--For Update**

   ```java
   public interface GoodsMapper {
        @Update("update t_goods set count=count-#{num} where id = #{id}")
        void updateNum(Map<String,Object> params);
   
        @Select("select * from t_goods where id = #{id} for update")
        Goods laodById(Long id);
   }
   ```

   就是通过For Update的思想在查询对象的时候就加锁，其他线程在查询的时候就必须等待，性能太差！

   这样虽然也能实现分布式锁的效果，但是性能差容易出现性能瓶颈

   好处：简单易用，好理解，保障数据强一致性

   缺点：

   1. select 的 for update 操作是基于间隙锁（gap lock） 实现的，是一种悲观锁的实现方式，所以存在阻塞问题
   2. 高并发情况下，大量请求进来，会导致大部分请求进行排队，影响数据库稳定性，也会耗费服务的CPU等资源
   3. 当获得锁的客户端等待时间过长时，会提示：[40001][1205] Lock wait timeout exceeded; try restarting transaction,高并发情况下，也会造成占用过多的应用线程，导致业务无法正常响应
   4. 如果优先获得锁的线程因为某些原因，一直没有释放掉锁，可能会导致死锁的发生
   5. 锁的长时间不释放，会一直占用数据库连接，可能会将数据库连接池撑爆，影响其他服务
   6. MySql数据库会做查询优化，即便使用了索引，优化时发现全表扫效率更高，则可能会将行锁升级为表锁，此时可能就更悲剧了
   7. 不支持可重入特性，并且超时等待时间是全局的，不能随便改动

   **乐观锁-不上锁**

   直接用:表中添加一个时间戳或者版本号的字段来实现，`update account set version = version + 1 where id = #{id} and version = #{oldVersion} `当更新不成功，客户端重试，重新读取最新的版本号或时间戳，再次尝试更新，类似 CAS 机制，推荐使用

​		实际代码中可以写个while循环不断重试，版本号不一致，更新失败，重新获取新的版本号，直到更新成功。

理解: 其实就是用一个版本号来假设这个数据没有被别人修改过!

​		**基于数据库主键实现分布式锁**

​		意思就是通过一个表的主键这个特性(主键是唯一不重复的特性)，如果有多个请求同时提交到数据库的话，数据库会保证只有一个操作可以成功，那么我们就可以认为操作成功的那个线程获得了该方法的锁，当方法执行完毕之后，想要释放锁的话，删除这条数据库记录即可

![image-20211210203230586](https://gitee.com/miawei/pic-go-img/raw/master/imgs/image-20211210203230586.png)

​	**基于唯一索引实现分布式锁**

​	其实这个的意思跟上面也是一样的，都是利用了唯一性来进行上锁！ 

#### 3. Redis

​	实现分布式锁的原理也很简单，就是需要得有一把唯一且共享的锁，多个服务同时去获取锁，但是只有一个服务才能获取到锁，其他没有获取到锁的服务需要等待或者自旋，等获取到锁的服务业务执行完成释放锁，其他的服务就可以再次尝试获取锁。

步骤：

1. 加锁-释放锁：

   ```
   我们可以使用redis的指令setnx,这个指令的好处就在于只有目标key不存在那么才会创建值, 如果存在那么就不做任何操作
   执行业务逻辑后在执行del指令就删除该key
   ```

2. 锁超时:

   ```
   在释放锁的阶段的时候如果出现宕机那么这个锁就会容易造成永远释放不了,出现死锁的一个状况!
   我们可以使用Redis的 expire（lock_stock，30）命令实现,即使宕机那么也可以出现key的自动删除
   ```

3. 原子性问题:

   ```java
   如果出现极端问题,如果setnx上锁操作还未来得及expire设置过期时间,那么就宕机了,那么我们可以就需要保证一个setnx和expire的原子性
   SET key value [EX seconds] [PX milliseconds] [NX|XX]
   如:
   if（set(lock_stock,1,"NX","EX",5) == 1）{	//获取锁并设置超时
       try {
           业务代码
       } finally {
           del（lock_stock）			 		//释放锁
       }
   }
   ```

4. 锁误删问题:

   ```java
   还有一种情况: 如果服务A在执行代码的期间因为执行较长然后key就自动过期了,然后执行到del()删除key的时候由于其他服务进来了,那么此时就会出现删除其他服务锁的一个情况发生!
   解决办法:
   我们可以在删除锁的时候先判断一下要删除的锁是不是自己上的锁，比如可以把锁的值使用一个UUID，在释放锁的时候先获取一下锁的值和当前业务中创建的UUID是不是同一个，如果是才执行·del删除锁，当然也可以使用线程的ID替代UUID
   如:
   String uuid = UUID.randomUUID().toString();
   if（jedis.set(lock_stock,uuid,"NX","EX",5) == 1）{	//获取锁并设置超时
       try {
           业务代码
       } finally {
           String lockValue = jedis.get(lock_stock);	//获取锁的值
           if(lockValue.equals(uuid)){			//判断是不是自己的锁
               jedis.del（lock_stock）			 	  //释放锁
           }
       }
   }
   ```

5. 第二轮误删问题:

   ```java
   这里误删和判断锁不是原子性的,也就是说容易出现服务A在获取锁判断也是当前锁的情况下,走到if里面准备删key的时候,突然key就突然过期了,那么此时别的服务又挤进来了,此时就容易出现误删其他服务锁的问题,那么我们就需要保证这组操作保证一个原子性问题!
   Lua脚本:
   String uuid = UUID.randomUUID().toString();
   if（jedis.set(lock_stock,uuid,"NX","EX",5) == 1）{	//获取锁并设置超时
       try {
           业务代码
       } finally {
           //lua脚本
           String script = "if redis.call('get', KEYS[1]) == ARGV[1] then return redis.call('del', KEYS[1]) else return 0 end";
           //执行脚本
           jedis.eval(script, Collections.singletonList("lock_stock"),Collections.singletonList(uuid));
       }
   }
   ```

6. 完整代码:

   ```java
   上面假如服务A获取锁进去了而服务B获取锁失败了,那么是不是就这样算了,这是不行的,我们需要让他等待片刻再次获取锁
   public void method(){
   	String uuid = UUID.randomUUID().toString();
   	if（jedis.set(lock_stock,uuid,"NX","EX",5) == 1）{	//获取锁并设置超时
   	    try {
   	        业务代码
   	    } finally {
   	        //lua脚本
   	        String script = "if redis.call('get', KEYS[1]) == ARGV[1] then return redis.call('del', KEYS[1]) else return 0 end";
   	        //执行脚本
   	        jedis.eval(script, Collections.singletonList("lock_stock"),Collections.singletonList(uuid));
   	    }
   	}else{
   		//休眠一会儿，重入方法，尝试获取锁
   		Thread.sleep(100);
   		method();	//自旋，重新进入方法
   	}
   }
   ```

理解: 在redis中使用分布式锁就是采用的setnx的方式, 首先会通过UUID来作为锁的value，这样就能保证跟别的服务不是同一把锁造成的误删问题，因为容易出现瞬间并发情况都是同时进入到if判断中， 然后通过固定的key的名称去设置新的value，如果这个key还存在那么就说明这个锁是有人的，那么就会进入休眠状态然后再一次尝试获取锁，而执行if中的组合命令也就意味着能够保证set和设置过期是同时发生的，然后执行完代码那么最终也是会通过原子性lua脚本去获取锁然后判断跟当前的uuid作为的value是否一样，如果不一样那么就不执行删除操作，因为我认为这锁已经过期了已经是别人的锁了！

为什么要设置uuid作为value？

​	因为在执行删除锁的操作的时候容易出现当前锁过期而别的服务进来那么就删除的是其他服务的锁，毕竟redis中删除key会将这个key删除，所以这个时候就需要来判断value表示是否是当前锁

----

**Redisson实现分布式锁**

它呢就是封装了我们上面的细节问题,从而让开发变得更简单!

如: 

1. 一个简单的分布式锁案例:

   ```java
    	@Test
       public void testLock2(){
       
           RLock rLock = redissonClient.getLock("lock_stock");
       	// 加锁以后10秒钟自动解锁
   		// 无需调用unlock方法手动解锁
   		rLock.lock(10, TimeUnit.SECONDS);
           try{
               System.out.println("加锁成功....");
               System.out.println("执行业务....");
           }finally {
               rLock.unlock();
               System.out.println("释放锁....");
           }
       }
   
   ```

   Redisson对分布式锁实现细节进行了封装，帮我们处理了分布式锁面临的一些列问题，那么Redisson是如何工作的呢？？？

   1. 如果没有设置过期时间，Redisson以 30s 作为锁的默认过期时间，获取锁成功后(底层也用到了Lua脚本保证原子性)`会开启一个定时任务定时进行锁过期时间续约，即每次都把过期时间设置成 30s，定时任务 10s执行一次(看门狗)`
   2. 如果设置了过期时间，直接把设定的过期时间作为锁的过期时间，然后使用Lua脚本获取锁，没获取到锁的线程会while自旋重入不停地尝试获取锁，当然指定了解锁时间，Redisson就不会再自动续期，那么如果在线程A业务还没执行完就自动解锁了，这时候线程B获取到锁，继续执行业务，那么等线程A业务执行完释放锁就可能会把线程B的锁删除，当然这种情况Redisson会`报异常`，但是这种情况是没有把所有线程都锁住的，所以如果要`手动设定过期时间需要让过期时间比业务逻辑执行的时间长才对`!

   **信号量**

​	信号量可以看做是在Redis中保存了一个数字，然后可以实现原子性的加或者减，比如说有一商品需要拿100个做秒杀，我们就可以把这个库存数量做成信号量，然后实现`原子性加减操作`!

```java
@Test
public void testReadLock5() throws InterruptedException {
    //获得到一个信号量
    RSemaphore semaphore = redissonClient.getSemaphore("semaphore");
    //设置信号量的值
    boolean setPermits = semaphore.trySetPermits(1000);
    System.out.println(setPermits);
    System.out.println("可用数量："+semaphore.availablePermits());

}
@Test
public void testReadLock6() throws InterruptedException {
    //获得到一个信号量
    RSemaphore semaphore = redissonClient.getSemaphore("semaphore");
    //获取 2 个信号量 ， 值会减去 2 ， 如果获取不到，方法会阻塞
    semaphore.acquire(2);
    System.out.println("可用数量："+semaphore.availablePermits());

    //尝试获取 2 个信号量 ， 值会减去 2 ， 如果获取不到，方法不会
    boolean tryAccquireSuccess = semaphore.tryAcquire(2);
    System.out.println(tryAccquireSuccess);
    System.out.println("可用数量："+semaphore.availablePermits());

}

@Test
public void testReadLock7() throws InterruptedException {
    //获得到一个信号量
    RSemaphore semaphore = redissonClient.getSemaphore("semaphore");
    //释放2个值，数量会加回去
    semaphore.release(2);
    System.out.println("可用数量："+semaphore.availablePermits());
}

```

理解: 这个信号量它呢我们一般用于秒杀的超卖问题，也就是说这个他能保证库存数量做为一个原子性操作，也就是说不会出现原本卖5件结果超卖到6件问题！



#### 4.zookeeper

这个我就不做笔记了，因为不会，即使做笔记也说不好！

节点分类：

1. 持久节点
   - 节点创建后，就一直存在，直到有删除操作来主动清除这个节点
2. 持久顺序节点
   - 父节点会为他的第一级子节点维护一份时序，会记录每个子节点创建的先后顺序
   - ZK会自动为给定节点名加上一个数字后缀，作为新的节点名。这个数字后缀的范围是整型的最大值
3. 临时节点
   - 客户端会话失效，那么这个节点就会自动被清除掉
   - 在临时节点下面不能创建子节点
4. 临时顺序节点
   - 在临时节点的基础上增加了顺序，可以用来实现分布式锁



![image-20211210211736705](https://gitee.com/miawei/pic-go-img/raw/master/imgs/image-20211210211736705.png)



#### 5.总结

![image-20211210211603900](https://gitee.com/miawei/pic-go-img/raw/master/imgs/image-20211210211603900.png)



## 12. 秒杀

秒杀问题解决方案:

#### 1.1.静态资源加速

- 页面静态化&动静分离

我们从前端说起，秒杀意味着大用户量和高并发请求，对于商品秒杀详情页来说页面的数据加载会给服务器带来很大的压力，可以把秒杀详情页静态化，反正这个页面的大部分`数据都是固定不变的`，然后把静态资源部署到`Nginx实现动静分离`

- CDN静态资源加速

页面静态化+动静分离后，客户端直接从Nginx访问完整的静态页面，无需再发送Ajax请求从后端加载动态数据，减轻了服务器压力，提高了页面响应速度，这里可以进一步优化，就是将静态资源缓存起来，比如静态资源上CDN后，客户端可以`从最近的CDN服务器节点获取静态资源`，加快响应速度

#### 2.2.流量控制

- 前端流控

秒杀系统的并发非常的高，然后能够秒杀到商品的请求是很少的，大部分的请求都是无效的请求，我们需尽可能的减少没不要的流量，前端限流指的是从前端限制请求的并发量

1. `随机丢弃请求`

   当用户进行秒杀，先在前端产生随机数，如果随机数满足某个条件，值在某个范围才有秒杀资格，否则直接秒杀失败。

   **在JS中生成一个范围比如：10 - 20 ，然后用户点击秒杀按钮的时候，随机生成一个数字，如果在 10 - 20 的范围内，就有秒杀资格，否则就么有秒杀资格，提示秒杀失败**。 -  一般不用

2. `置灰秒杀按钮`

   比如未到秒杀时间禁用秒杀按钮，点击了秒杀按钮后马上禁用按钮，需要`等n秒才能点击第二次等来减少用户的请求数量`

3. `流量错峰`

   流量错峰就是尽可能的将流量分散到更大范围的时间点，比如`秒杀时加入图片验证码`，或者需要答题，每个人输入图片验证码的时间都不一样，相当于就是把流量分散了 ，也可以延迟秒杀，点击了秒杀按钮，0 - 5 秒后才发送秒杀请求，这样也能流量错峰。

   或者随机延迟发送秒杀请求到后台。

- 后端流控

  前端限流能够减少很少一部分并发，大量的请求还是会打到后端服务器，如果我们的服务器无法应对这么高的并发可能会被流量击垮，保守起见我们可以通过后端限流手段把多余的流量排除在外，那么实实在在参与秒杀的流量又少了很大一部分。`通常会使用Nginx+Lua进行流控。或者在应用层流控，限流的组件常用的有Sentinel、Hystrix等`

- 秒杀预约

  如果预计流量特别大，可以做一个秒杀预约系统，只有`报了名的才有秒杀资格参与秒杀`，这样就可以排除很多用户了。

#### 2.3.恶意防刷

- 秒杀链接加密&隐藏

秒杀地址不能提前暴露，因为有被提前秒杀的风险，即使秒杀逻辑做了秒杀时间判断，如果秒杀地址被暴露，使用程序不停获取最新时间不停刷秒杀接口，那被秒杀到的机率是非常高的，可能所有的商品都被程序秒杀到。那如何实现连接不被暴露呢？可以`把URL动态化，使用MD5加密，通过前端获取URL，后端进行校验`。

- 恶意请求拦截

对于恶意的请求要做拦截处理，否则会给系统带来没必要的流量，这种恶意请求一般是通过程序或脚本不停的发请求，这种情况请求会消耗带宽不说还可能造成缓存击穿，甚至把服务器打崩。可以`使用Ningx+Lua实现`，比如`1个IP 1秒中只允许发送1个请求，或者一个用户ID 1秒钟只能发送1个请求，也对IP地址做一个黑名单，或者对用户做一个黑名单`。

#### 2.4.服务隔离

- 数据库隔离&业务隔离

为了让秒杀有更充足的资源不和别的服务抢占资源，需要将`秒杀系统独立出来`，这里分为：业务独立，服务独立，数据独立，独立的秒杀微服务和独立的数据库，同时秒杀服务也应该具有伸缩性，`可集群`，这样的系统才能支持更高的并发

#### 2.5.秒杀缓存

如果大量请求进来，打到数据库，数据库压力太大

- 库存预热

秒杀设计到库存判断和减库存，通常有“付款减库存”，“下单减库存”和“预减库存”等方式，对于秒杀而言，`如果每次秒杀都需要先去数据库检查库存，然后再扣减库存，然后再保存订单数据，那在高并发请求下数据库是吃不消的`，性能也会特别差，所以这里可以使用“预减库存”方案。



非关系学数据库的出现就是为了解决传统关系型数据库在性能上的不足，`我们可以把商品库存事先存储到Redis中，每次秒杀商品时去Redis检查库存，同时基于Redis扣减库存，事后可以异步更新到数据库，这里Redis就解决了数据库性能问题`，让秒杀流程变得更高效，但是如果有比较复杂的减库存逻辑，或者需要使用事务，你还是必须在数据库中完成减库存--我们可以考虑用信号量来做

这里还有一个问题，如果是一般的秒杀并发没有太高的话，一个Redis即可，几万的并发还是扛得住，但是如果要支持更高的并发量，那可能一个Redis就吃不消了，可以考虑Redis集群

- 秒杀商品缓存预热

把秒杀的商品相关数据缓存起来，减少和数据库的交流提高响应速度，最好的方案就是把秒杀商品缓存到Redis中，秒杀逻辑从Redis中进行读写。

#### 2.6.消峰&降级

- MQ队列消峰

下单是一个很耗时的工作，除了设计到大量的业务外还要和数据库进行交流，秒杀系统要的就是快，如果一个秒杀请求进来秒杀到商品后需要等待下单流程执行完成之后才返回结果，那这个请求是很耗时的，在高并发请求下系统的吞吐量就会很低，为了提高请求响应速度，可以采用异步下单，当秒杀服务秒杀到商品后，直接往MQ扔一个下单消息后就可以返回消息给用户，提示秒杀成功，而订单服务监听下单消息，获取消息后就执行下单逻辑即可，这样一来秒杀逻辑是非常快速的，因为采用异步下单，秒杀服务不用等待下单完成即可返回结果，同时也起到了一个消除峰值的效果，因为下单消息都在MQ排队呢

- 熔断降级

熔断降级是必须的，如果系统真的顶不住了，不做熔断降级措施可能整个系统都会瘫痪，做了降级至少对故障服务隔离掉，返回兜底数据，不至于服务器直接瘫痪全是500,404什么的。



#### 2.7.超卖&少卖

- 超卖问题

这是一个比较重要的话题，在高并发请求下很容易出现超卖，比如三个秒杀服务都判断到还剩1一个库存，三个秒杀服务都去扣减库存，那库存就会被减成-2,这就出现了超卖了。这个问题可以使用分布式锁来解决，让多个服务对库存的扣减操作成原子性。可以`使用Redis的信号量实现`

- 支付超时(少卖问题)

秒杀到商品后即可生成订单号，然后使用该订单号下单，下单采用MQ异步下单，秒杀服务往MQ扔一个小单消息，订单服务作为消费者从MQ取消息然后进行下单。秒杀成功秒杀服务就可以返回，用户即可根据订单号完成支付，支付成功后修改订单状态。那如果用户秒杀到商品后迟迟未支付呢？我们是不是需要为支付超时的订单退回库存呢？

这里可以使用`延迟队列实现`，下单成功后放入一个订单消息到延迟队列A，达到超时时间的消息成为死信消息，消息会通过一个死信交换机转发到另外一个队列B，我们可以指定一个消费者从该队列B中消费消息，判断支付状态如果支付超时，就做退库存操作。

#### 2.8.其他问题

- 网络开销

如果一个请求经过的服务太多注定比较耗时，每一次服务的调用都是网络开销，所以尽可能的减少服务的调用，在上面的秒杀案例流程图中其实网关层可以去掉请求直接使用Nginx负载到秒杀服务，减少网络开销，或者也可以请求直接走网关不走Nginx来减少网络开销，同时数据要少，网络传输尽可能少的数据来提高网络传输速度(select * 的不要)，甚至可以使用压缩传输，当然压缩又会增加CPU的消耗

建构图:

![1638960437555](https://gitee.com/miawei/pic-go-img/raw/master/imgs/1638960437555.png)



执行流程(理解):

1. 在后台通过定时调度任务将需要秒杀的课程发布到Redis中，使用的是Hash的数据结构进行存储和方便更改；

2. 用户在前台通过redis中展示的秒杀课程进行秒杀，这时为了削减前端的并发那么我们可以采用按钮置灰、验证码来达到一个削峰的目的！

3. 点击秒杀然后就会通过DNS然后使用Lvs+Nginx来达到一个负载均衡限流的作用!

4. 这时就会进入到秒杀集群也就是redis集群中，然后采用的是”预减库存“的这个方案，也就是在进入这个阶段那么我们就采用redisson的信号量来进行解决超卖这个问题，减去库存以后我们就创建一个预创订单放进redis缓存中，然后发送消息到延迟队列中用于判断下单超时退库存的一个问题！

5. 创建好以后我们就将订单号返回给客户端，客户端拿到订单号在订单详情页去发起下单的这个服务，在服务中我们可以将业务单进行入库，那么这个时候就会存在一个极端的问题， 如果用户在将业务单入库的时候这个预创订单过期了退库存了怎么办？

   ```
   在初创订单这里放入mq过期队列中, 设置时间通过死信交换机和死信队列, 然后我们定义一个消费者去监听死信队列, 在时间到期后根据redis预创订单的key去获取, 如果获取到那么就认为这个订单还没保存到数据库中, 那么我们就退库存! 
   为什么要放入过期队列中, 因为一旦初创订单那么我就认为这个订单会带给前端,前端就带到订单服务中去保存到数据库中, 那么就会删除redis中的预创订单, 如果在指定时间以内我们还没保存到数据库我们就认为这个订单已经超时了!
   
   问题: 在死信队列中如果正在推库存的时候刚好用户点击下单那么此刻怎么办?
   我们可以让这两个加一个分布式锁 两个只有一个能操作--- redis实现分布式锁
   我们可以设置消息过期为30分钟,而给用户提示说你还有25分钟支付时间, 那么就会有相差5分钟时间的空档期, 那么我们就可以保证不会出现这个操作了!
   ```

6. 将订单保存到业务单数据库以后然后还要保存支付单，然后这个时候还要发一个消息到延迟队列，用于判断指定时间内如果用户未支付也就是说可能在支付密码界面就不动了，那么这个时候我们就要去使用MQ消费者去手动取消订单退库存！

7. 返回给客户端订单号，然后请求到支付服务，支付服务就获取支付单创建一个支付流水表，然后根据支付的状态来进行处理，这里还有一个MQ，是用于将支付结果异步通知。比如修改业务单状态然后还要将保存订单所在的课程和用户之间的关系！

Xmid:

![image-20211211192006930](https://gitee.com/miawei/pic-go-img/raw/master/imgs/image-20211211192006930.png)

![image-20211211192021099](https://gitee.com/miawei/pic-go-img/raw/master/imgs/image-20211211192021099.png)



## 13. BIO&NIO&AIO理解

同步（异步）: 如在A线程中开了一个B线程，那么就得必须等到B线程执行结束才能获取到结果执行后续的代码！这就是同步，反之就不需要等待B线程就可以执行后续的事情！只需要后面通过回调机制来获取B线程的结果即可！

阻塞（非阻塞）：阻塞是指I/O操作需要彻底完成后才能返回用户空间 ，非阻塞是指I/O操作被调用后立即返回一个状态值，无需等I/O操作彻底完成--如使用read读取数据，如果一直读取不到那么就会一直处于等待，这就是阻塞，而非阻塞就反之就不需要等待就可以往后执行！



BIO：

概念：同步阻塞型IO，该模式是一个请求一个线程并且读取数据是必须获取到数据才能返回否则处于阻塞等待。

优化方案：使用线程池！

缺点：并发大会创建大量的线程，比较占用系统资源！容易造成阻塞等待消耗不必要的线程开销！

优点：程序简单容易理解



NIO:

概念：同步非阻塞型IO，一个线程处理多个请求，发起的请求会进行一个“多路复用”去处理，一个请求如果获取不到数据那么就不会进行阻塞就会去做其他的一些事情！



AIO：

概念：NI02.0 是属于异步非阻塞模型，是对NIO的一个增强！



```
NIO和BIO的区别:
1. BIO以流的方式处理数据，NIO以块（buffer）的方式处理数据，块的IO效率高于流的IO效率
2. BIO是阻塞IO，NIO是非阻塞IO
3. BIO使用字符流，或者字节流进行操作，而NIO基于channel通道和buffer缓冲区进行操作
4. BIO适用于并发低的业务场景，NIO适用于并发高的业务场景！
```



## 14. Spring事务的传播方式

传播方式主要是指多个事务同时存在时，在Spring如何处理事务, 它们是否需要在同一个事务中运行，一个事务的方法被另外有事务的方法调用时，这个事务应该如何运行；

主要有四种：

1. required: 支持当前事务，当前方法有事务就用当前的事务，没有事务就新建一个。

   ```java
   @Transactional(propagation = Propagation.REQUIRED,isolation = Isolation.DEFAULT)
   public int incr(int balance, int id) {
       //传播方式request
       int result = studentMapper.updateBalance(balance, id);
       //新事务
       studentService.decr(-100, 2);
       //制造异常引起incr这个事务回滚
       int i = 1/0;
       return result ;
   }
   @Transactional(propagation = Propagation.REQUIRED,isolation = Isolation.DEFAULT,rollbackFor = Throwable.class)
   public int decr(int balance, int id){
       int result = studentMapper.updateBalance(balance, id);
       return result ;
   }
   结果:decr加入到了incr这个事务中,incr回滚导致decr也回滚
   ```

   理解：就是说“decr”这个事务就加入到incr这个事务，如果incr有事务那么就用当前的事务，如果没有就新建一个，总之就保持在同一个事务中运行！

2. required_new: 不管当前有没有事务，都新建一个事务，用自己的事务

   ```java
   //表示不管是否存在事务，都创建一个新的事务，原来的事务挂起，新的事务执行完毕，继续执行老的事务；
   @Transactional(propagation = Propagation.REQUIRED,isolation = Isolation.DEFAULT)
   public int incr(int balance, int id) {
       //传播方式request
       int result = studentMapper.updateBalance(balance, id);
   
       //新事务
       studentService.decr(-100, 2);
       //制造异常
       int i = 1/0;
       return result ;
   }
   
   /** 转出 */
   @Transactional(propagation = Propagation.REQUIRES_NEW,isolation = Isolation.DEFAULT,rollbackFor = Throwable.class)
   public int decr(int balance, int id) {
       int result = studentMapper.updateBalance(balance, id);
       return result ;
   }
   //结果:而结果是decr这个事务不会被incr影响,最终导致"增加"这个事务回滚,"减少"这个事务会正常提交
   ```

   理解：“减少”这个事务不管你“增加”这个事务是否有事务，那么我都会新建一个事务然后执行，等待我执行完毕再执行你这个“新增”的事务，那么这种我感觉就纯粹两个事务了，因为这就是分开了，“增加”这个事务遇到异常会进行回滚而”减少“这个事务本身没有异常那么正常提交！

3. supports: 当前有事务则用当前事务，没有事务就不用回滚

   ```java
   //表示如果当前存在事务，就加入该事务；如果当前没有事务，那就不使用事务；
   /** 转入 */
   @Override
   public int incr(int balance, int id) {//没有事务
       //传播方式request
       int result = studentMapper.updateBalance(balance, id);
   
       //新事务
       studentService.decr(-100, 2);
       int i = 1/0;
       return result ;
   }
   
   /** 转出 */
   @Transactional(propagation = Propagation.SUPPORTS,
                  isolation = Isolation.DEFAULT,
                  rollbackFor = Throwable.class)
   public int decr(int balance, int id) /*throws SQLException */{
       int result = studentMapper.updateBalance(balance, id);
   
       //throw new SQLException("SQL异常");
       return result ;
   }
   结果:incr 和 decr都没有事务,即使报了异常,也都操作成功了,反之我们给incr设上事务
   ```

   其他测试:

   ```java
   @Transactional(propagation = Propagation.REQUIRED,isolation = Isolation.DEFAULT )
   public int incr(int balance, int id) {
       //传播方式request
       int result = studentMapper.updateBalance(balance, id);
   
       //新事务
       studentService.decr(-100, 2);
       int i = 1/0;
       return result ;
   }
   
   /** 转出 */
   @Override
   @Transactional(propagation = Propagation.SUPPORTS,isolation = Isolation.DEFAULT,rollbackFor = Throwable.class)
   public int decr(int balance, int id) /*throws SQLException */{
       int result = studentMapper.updateBalance(balance, id);
   
       //throw new SQLException("SQL异常");
       return result ;
   }
   //结果:是decr进入了incr这个事务,两者都回滚了,对数据库没有影响
   ```

4. not_supports: 以非事务运行，存在事务则将事务挂起，就是不用事务！

   ```java
   //表示不使用事务；如果当前存在事务，就把当前事务暂停，以非事务方式执行；
   /** 转入 */
   public int incr(int balance, int id) {
       //传播方式request
       int result = studentMapper.updateBalance(balance, id);
   
       //新事务
       studentService.decr(-100, 2);
       int i = 1/0;
       return result ;
   }
   
   /** 转出 */
   @Transactional(propagation = Propagation.NOT_SUPPORTED,isolation = Isolation.DEFAULT,rollbackFor = Throwable.class)
   public int decr(int balance, int id) /*throws SQLException */{
       int result = studentMapper.updateBalance(balance, id);
   
       //throw new SQLException("SQL异常");
       return result ;
   }
   //结果:是两者都没了事务,抛异常没有影响
   ```

   

剩下三种：不常用：

5. Never: 以非事务方式运行，就是不用事务，如当前存在事务则抛出异常
6. Nested: 如果当前存在事务，则在嵌套事务内执行，如果当前没有事务，则新建一个事务
7. Mandatory: 支持当前事务，如果当前没有事务，就抛出异常。

 